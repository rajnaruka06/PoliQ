{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 of AI_Stuff and ChatHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from AI_Stuff.Agent_Helpers import load_elecdata_postgres, clean_sql_query, SQLCoder, DDLCommandException, ChatHistory\n",
    "# from AI_Stuff.CustomAgents import SQLExpert, ResponseSummarizer\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# db = load_elecdata_postgres()\n",
    "# dialect = db.dialect\n",
    "# llm = ChatOpenAI(\n",
    "#     model=\"gpt-4o\",\n",
    "#     temperature=0,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     max_retries=2\n",
    "# )\n",
    "\n",
    "# schema_info = db.get_table_info()\n",
    "# sql_coder_agent = SQLExpert(llm = llm)\n",
    "# sql_query_tool = SQLCoder(db=db)\n",
    "# response_summarizer_agent = ResponseSummarizer(llm=llm)\n",
    "# history = ChatHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Works\n",
    "\n",
    "# from AI_Stuff.Workflows import elecdataworkflow\n",
    "# workflow = elecdataworkflow()\n",
    "# workflow.run(user_query=\"How many votes did each party get in the 2022 election?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Works\n",
    "\n",
    "# history = ChatHistory()\n",
    "# user_query = \"How many votes did each party get in the 2022 election?\"\n",
    "# sql_query = \"\"\n",
    "# response = \"\"\"### Summary of Votes by Party in the 2022 Election\n",
    "\n",
    "# #### Key Insights:\n",
    "# 1. **Top Parties by Votes:**\n",
    "#    - **Liberal Party** received the highest number of votes with **2,712,423** votes.\n",
    "#    - **Australian Labor Party** followed with **2,445,090** votes.\n",
    "#    - **Labor** (likely a duplicate or regional representation) garnered **1,290,950** votes.\n",
    "\n",
    "# 2. **Other Notable Parties:**\n",
    "#    - **Pauline Hanson's One Nation**: 562,511 votes.\n",
    "#    - **The Greens**: 963,961 votes.\n",
    "#    - **Independent** candidates collectively received 639,217 votes.\n",
    "#    - **Liberal National Party of Queensland**: 858,118 votes.\n",
    "\n",
    "# 3. **Smaller Parties and Independents:**\n",
    "#    - **United Australia Party**: 483,854 votes.\n",
    "#    - **The Nationals**: 457,945 votes.\n",
    "#    - **Queensland Greens**: 287,066 votes.\n",
    "#    - **Informal votes** (likely spoiled or invalid ballots): 674,035 votes.\n",
    "\n",
    "# 4. **Minor Parties and Low Vote Counts:**\n",
    "#    - Several minor parties received fewer than 50,000 votes each, such as **Australian Federation Party** (44,309 votes), **Shooters, Fishers and Farmers Party** (14,934 votes), and **Animal Justice Party** (61,698 votes).\n",
    "#    - Some parties received very minimal support, such as **Australian Democrats** (525 votes), **Reason Australia** (1,015 votes), and **Drew Pavlou Democratic Alliance** (848 votes).\n",
    "\n",
    "# #### Trends and Observations:\n",
    "# - **Dominance of Major Parties**: The Liberal and Labor parties dominate the vote count, collectively receiving over 6 million votes.\n",
    "# - **Significant Support for Minor Parties**: Parties like Pauline Hanson's One Nation and The Greens have substantial support, indicating a diverse political landscape.\n",
    "# - **High Number of Informal Votes**: The informal vote count is notably high at 674,035, which could indicate voter confusion or dissatisfaction.\n",
    "# - **Regional Variations**: The presence of parties like the Liberal National Party of Queensland and Queensland Greens suggests regional political dynamics.\n",
    "\n",
    "# #### Detailed Vote Counts:\n",
    "# - **Liberal Party**: 2,712,423 votes\n",
    "# - **Australian Labor Party**: 2,445,090 votes\n",
    "# - **Labor**: 1,290,950 votes\n",
    "# - **Pauline Hanson's One Nation**: 562,511 votes\n",
    "# - **The Greens**: 963,961 votes\n",
    "# - **Independent**: 639,217 votes\n",
    "# - **Liberal National Party of Queensland**: 858,118 votes\n",
    "# - **United Australia Party**: 483,854 votes\n",
    "# - **The Nationals**: 457,945 votes\n",
    "# - **Queensland Greens**: 287,066 votes\n",
    "# - **Informal**: 674,035 votes\n",
    "\n",
    "# #### Minor Parties (Selected):\n",
    "# - **Australian Federation Party**: 44,309 votes\n",
    "# - **Shooters, Fishers and Farmers Party**: 14,934 votes\n",
    "# - **Animal Justice Party**: 61,698 votes\n",
    "# - **Australian Democrats**: 525 votes\n",
    "# - **Reason Australia**: 1,015 votes\n",
    "# - **Drew Pavlou Democratic Alliance**: 848 votes\n",
    "\n",
    "# This summary provides a comprehensive overview of the vote distribution among various parties in the 2022 election, highlighting the dominance of major parties, the significant support for minor parties, and the notable number of informal votes.\"\"\"\n",
    "# chat = f\"\"\"User Query: {user_query}\\nSQL Query: {sql_query}\\nResponse: {response}\"\"\"\n",
    "# history.add(chat)\n",
    "# history.add(chat)\n",
    "# print([len(chat) for chat in history.get().split('\\n---\\n')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 of try1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:8000/run\"\n",
    "data = {\"user_query\": \"How many votes did each party get in the 2022 election?\"}\n",
    "headers = {\"accept\": \"application/json\", \"Content-Type\": \"application/json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url, json=data, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: ChatHistory V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Stuff.Agent_Helpers import ChatHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatHistory(user_id=\"test_user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding Functionality\n",
    "chat_id_1 = chat_history.addMessage(None, \"New Message Chat ID 1\")\n",
    "chat_id_2 = chat_history.addMessage(None, \"New Message Chat ID 2\")\n",
    "chat_history.addMessage(chat_id_1, \"chatid one append 1\")\n",
    "chat_history.addMessage(chat_id_2, \"chatid two append 1\")\n",
    "chat_history.addMessage(chat_id_1, \"chatid one append 2\")\n",
    "chat_history.addMessage(chat_id_2, \"chatid two append 2\")\n",
    "\n",
    "print(f\"chat id 1: {chat_id_1}, chat id 2: {chat_id_2}\")\n",
    "\n",
    "## Retrieving Functionality\n",
    "all_chats = chat_history.get_all_chats()\n",
    "print(\"All chats:\")\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Retrieving specific chat\n",
    "messages = chat_history.get_messages(chat_id_1)\n",
    "print(\"\\nMessages for chat_id_1:\")\n",
    "for message in messages:\n",
    "    print(message)\n",
    "\n",
    "## Retrieving most recent chats\n",
    "recent_chats = chat_history.get_recent_messages(chat_id=chat_id_1)\n",
    "print(\"\\nMost recent chats:\")\n",
    "for chat in recent_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Pinning Unpinning\n",
    "chat_history.pin_chat(chat_id_1)\n",
    "print(\"\\nChat_id_1 pinned.\")\n",
    "all_chats = chat_history.get_all_chats()\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "chat_history.unpin_chat(chat_id_1)\n",
    "print(\"Chat_id_1 unpinned.\")\n",
    "all_chats = chat_history.get_all_chats()\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Archiving\n",
    "chat_history.archive_chat(chat_id_2)\n",
    "print(\"\\nChat_id_2 archived.\")\n",
    "\n",
    "## Test Search\n",
    "search_results = chat_history.search_chats(\"services\")\n",
    "print(\"\\nSearch results for 'services':\")\n",
    "for result in search_results:\n",
    "    print(result)\n",
    "\n",
    "## Test Delete\n",
    "chat_history.delete_chat(chat_id_1)\n",
    "print(\"\\nChat_id_1 deleted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: try3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "base_url = \"http://127.0.0.1:8000\"\n",
    "\n",
    "def test_fetch_chat_history(user_id):\n",
    "    response = requests.get(f\"{base_url}/api/chats/all\", params={\"user_id\": user_id})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "def test_fetch_messages(chat_id, user_id):\n",
    "    response = requests.get(f\"{base_url}/api/chats/{chat_id}/messages\", params={\"user_id\": user_id})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "    \n",
    "def test_handle_send(message_content, chat_id=None, user_id='test_user'):\n",
    "    payload = {\n",
    "        \"content\": message_content,\n",
    "        \"chat_id\": chat_id\n",
    "    }\n",
    "    response = requests.post(f\"{base_url}/api/messages/send\", params={\"user_id\": user_id}, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "def test_handle_pin_chat(chat_id, user_id='test_user'):\n",
    "    response = requests.put(f\"{base_url}/api/chats/{chat_id}/pin\", params={\"user_id\": user_id})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "def test_handle_delete_chat(chat_id, user_id='test_user'):\n",
    "    response = requests.delete(f\"{base_url}/api/chats/{chat_id}/delete\", params={\"user_id\": user_id})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "def test_handle_archive_chat(chat_id, user_id='test_user'):\n",
    "    response = requests.put(f\"{base_url}/api/chats/{chat_id}/archive\", params={\"user_id\": user_id})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "def test_handle_search(term, user_id='test_user'):\n",
    "    response = requests.get(f\"{base_url}/api/chats/search\", params={\"term\": term, \"user_id\": user_id})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "user_id = 'test_user'\n",
    "chat_id = '66c6b793a74702e24ff8a187'\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client['ChatHistoryDB']\n",
    "collection = db[str(user_id)]\n",
    "\n",
    "print(test_fetch_chat_history('test_user'))\n",
    "print(\"*--\"*20)\n",
    "print(test_fetch_messages(chat_id, 'test_user'))\n",
    "print(\"*--\"*20)\n",
    "print(test_handle_send(\"How many votes did each party get in the 2022 election?\"))\n",
    "print(\"*--\"*20)\n",
    "print(test_fetch_messages(chat_id, 'test_user'))\n",
    "print(\"*--\"*20)\n",
    "print(test_handle_pin_chat(chat_id, 'test_user'))\n",
    "print(collection.find_one({\"chat_id\": '66c6b793a74702e24ff8a187'}))\n",
    "print(\"*--\"*20)\n",
    "print(test_handle_search('election'))\n",
    "print(\"*--\"*20)\n",
    "print(test_handle_archive_chat(chat_id))\n",
    "print(collection.find_one({\"chat_id\": chat_id}))\n",
    "print(\"*--\"*20)\n",
    "print(test_handle_delete_chat(chat_id))\n",
    "print(collection.find_one({\"chat_id\": chat_id}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Unfold. Check Any part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Stuff.Agent_Helpers import load_elecdata_postgres, clean_sql_query, SQLCoder, DDLCommandException\n",
    "from AI_Stuff.CustomAgents import SQLExpert, ResponseSummarizer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = load_elecdata_postgres()\n",
    "dialect = db.dialect\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")\n",
    "schema_info = db.get_table_info()\n",
    "sql_coder_agent = SQLExpert(llm = llm)\n",
    "sql_query_tool = SQLCoder(db=db)\n",
    "response_summarizer_agent = ResponseSummarizer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What are the most recent 3 records in elecdata_senatepreference table\"\n",
    "\n",
    "sql_query = sql_coder_agent.generate_query(\n",
    "            user_query = user_query\n",
    "            , dialect='postgres'\n",
    "            , table_info=schema_info\n",
    "            , chat_history=''\n",
    "        )\n",
    "sql_query = clean_sql_query(sql_query)\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = sql_query_tool.query_runner.invoke(sql_query)\n",
    "# print(res)\n",
    "\n",
    "# import re\n",
    "# from decimal import Decimal\n",
    "\n",
    "# def _parse_decimal(match):\n",
    "#     value = match.group(1)\n",
    "#     return Decimal(value)\n",
    "\n",
    "\n",
    "# import datetime\n",
    "\n",
    "# def _parse_datetime(match):\n",
    "#     date_args = list(map(int, match.group(1).split(',')))\n",
    "#     if match.group(2):  # Check if 'tzinfo' is present in the match\n",
    "#         dt = datetime.datetime(*date_args, tzinfo=datetime.timezone.utc)\n",
    "#     else:\n",
    "#         dt = datetime.datetime(*date_args)\n",
    "#     return f\"'{dt.isoformat()}'\"\n",
    "# import ast\n",
    "\n",
    "# def _custom_parser(res_str: str):\n",
    "#     # Replace Decimal instances\n",
    "#     res_str = re.sub(\n",
    "#         r\"Decimal\\('([^']+)'\\)\",\n",
    "#         lambda m: str(_parse_decimal(m)),\n",
    "#         res_str\n",
    "#     )\n",
    "#     # Replace datetime.datetime instances with or without timezone\n",
    "#     res_str = re.sub(\n",
    "#         r\"datetime\\.datetime\\(([\\d, ]+)(, tzinfo=datetime\\.timezone\\.utc)?\\)\",\n",
    "#         _parse_datetime,\n",
    "#         res_str\n",
    "#     )\n",
    "#     # Safely evaluate the string as a literal\n",
    "#     return ast.literal_eval(res_str)\n",
    "\n",
    "\n",
    "# res = _custom_parser(res)\n",
    "# res = pd.DataFrame.from_records(data=res, columns=range(len(res[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CREATE\" in sql_query or \"DELETE\" in sql_query or \"UPDATE\" in sql_query or \"ALTER\" in sql_query:\n",
    "    raise DDLCommandException\n",
    "else:\n",
    "    data = sql_query_tool.execute_query(sql_query)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response_summarizer_agent.summarize(user_query=user_query, dataframe=data)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Workflow Cabilities (22 Aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Stuff.Workflows import elecdataworkflow\n",
    "import time\n",
    "workflow = elecdataworkflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions = [\"Analyze the distribution of vacancies across states in the elecdata_pool table. What observations can you make?\"\n",
    "#     ,\"Compare the quota values for different states in the elecdata_pool table. What might explain the differences?\"\n",
    "#     ,\"Examine the elecdata_senatepreference table. What patterns do you notice in the transfer of votes between candidates?\"\n",
    "#     ,\"Using the elecdata_candidatepreference table, calculate the total votes received and the percentage of total votes for each candidate in the sample.\"\n",
    "#     ,\"Analyze the elecdata_votestack table to identify any correlations between primary votes and the state or location of voting.\"\n",
    "#     ,\"Using the elecdata_votetally table, compare the performance of candidates across different voting methods (ordinary, postal, pre-poll, etc.). What trends do you observe?\"\n",
    "#     ,\"Examine the elecdata_senateround table. How does the number of rounds vary between different pools, and what might this indicate about the competitiveness of the elections?\"\n",
    "#     ,\"Combine data from the elecdata_contention and elecdata_votetally tables to analyze how ballot position correlates with the number of primary votes received. What conclusions can you draw?\"\n",
    "#     ,\"Using data from multiple tables (elecdata_houseelection, elecdata_seat, elecdata_contention, elecdata_votetally), perform a comprehensive analysis of voting patterns and party performance across different elections and regions. Identify any notable trends or shifts in voter behavior.\"\n",
    "# ]\n",
    "\n",
    "questions = [\"Analyze the distribution of vacancies across states. What observations can you make?\"\n",
    "    ,\"Compare the quota values for different . What might explain the differences?\"\n",
    "    ,\"What patterns do you notice in the transfer of votes between candidates?\"\n",
    "    ,\"Calculate the total votes received and the percentage of total votes for each candidate.\"\n",
    "    ,\"Identify any correlations between primary votes and the state or location of voting.\"\n",
    "    ,\"Compare the performance of candidates across different voting methods (ordinary, postal, pre-poll, etc.). What trends do you observe?\"\n",
    "    ,\"How does the number of rounds vary between different pools, and what might this indicate about the competitiveness of the elections?\"\n",
    "    ,\"Analyze how ballot position correlates with the number of primary votes received. What conclusions can you draw?\"\n",
    "    ,\"Perform a comprehensive analysis of voting patterns and party performance across different elections and regions. Identify any notable trends or shifts in voter behavior.\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    res = workflow.run(user_query=question)\n",
    "    print(f\"Question: {question}\\nResponse: {res}\\n\")\n",
    "    print('---'*20)\n",
    "    time.sleep(180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Agent_Helpers.py 23-Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from AI_Stuff.Agent_Helpers import load_polimap_postgres, load_elecdata_postgres, load_llm, web_search, SQLCoder, ChatHistory\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "import tiktoken\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PyPDF2 import PdfReader\n",
    "from pymongo import MongoClient, TEXT\n",
    "from bson import ObjectId\n",
    "import gridfs\n",
    "import io\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "from decimal import Decimal\n",
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test PostgreSQL database connection\n",
    "try:\n",
    "    db1 = load_polimap_postgres()\n",
    "    db2 = load_elecdata_postgres()\n",
    "    if isinstance(db1, SQLDatabase) and isinstance(db2, SQLDatabase):\n",
    "        print(\"Postgres connections successful.\")\n",
    "    else:\n",
    "        print(\"Error connecting to Postgres.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Postgres: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test LLM loading\n",
    "try:\n",
    "    openai_llm = load_llm(llm_name='gpt', model='gpt-4o')\n",
    "    anthropic_llm = load_llm(llm_name='claude', model='claude-3-opus-20240229')\n",
    "    if isinstance(openai_llm, ChatOpenAI) and isinstance(anthropic_llm, ChatAnthropic):\n",
    "        print(\"LLMs loaded successfully.\")\n",
    "    else:\n",
    "        print(\"Error loading LLMs.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading LLMs: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search(\"How many votes did each party get in the 2022 election?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SQLCoder\n",
    "try:\n",
    "    sql_coder = SQLCoder(db2)\n",
    "    query = \"\"\"SELECT primary_votes FROM elecdata_votestack where primary_votes = 434;\"\"\"\n",
    "    df = sql_coder.execute_query(query)\n",
    "    print(\"SQL Query Result:\", df)\n",
    "except Exception as e:\n",
    "    print(f\"Error executing SQL query: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ChatHistory 23-Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Stuff.Agent_Helpers import ChatHistory\n",
    "\n",
    "# Create an instance of the ChatHistory class\n",
    "chat_history = ChatHistory(user_id=\"test_user\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = chat_history.get_all_chats()\n",
    "chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add messages to a chat session\n",
    "chat_id = chat_history.add_message(chat_id='66c8c2e45dd82d23781eab0d', content=\"Yes, Shooot it!\", is_user=False)\n",
    "chat_history.add_message(chat_id=chat_id, content=\"Just testing\", is_user=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve messages for a chat session\n",
    "messages = chat_history.get_messages(chat_id)\n",
    "print(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.get_recent_messages(chat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "csv_file = b\"col1,col2\\nval1,val2\"\n",
    "file_id = chat_history.upload_doc(chat_id, csv_file, \"test.csv\", \"csv\")\n",
    "\n",
    "file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from fpdf import FPDF\n",
    "import tempfile\n",
    "\n",
    "# Create a simple PDF file\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "pdf.cell(200, 10, txt=\"Hello World!\", ln=True, align=\"C\")\n",
    "\n",
    "# Create a temporary file to save the PDF\n",
    "with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_file:\n",
    "    pdf.output(temp_file.name)\n",
    "    temp_file.seek(0)  # Move to the start of the file\n",
    "\n",
    "    # Read the file into a BytesIO object\n",
    "    pdf_file = temp_file.read()\n",
    "\n",
    "# Use the BytesIO object to upload the PDF document\n",
    "file_id = chat_history.upload_doc(chat_id, pdf_file, \"valid_test.pdf\", \"pdf\")\n",
    "print(f\"Uploaded Valid PDF Doc ID: {file_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get documents context\n",
    "doc_context = chat_history.get_documents_context(chat_id)\n",
    "print(f\"Document Context: {doc_context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search chats\n",
    "search_results = chat_history.search_chats(\"Hello\")\n",
    "print(f\"Search Results: {search_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Edge Cases# Invalid document type\n",
    "try:\n",
    "    chat_history.upload_doc(chat_id, csv_file, \"test.txt\", \"txt\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty messages\n",
    "chat_id_empty = chat_history.add_message(chat_id=None, content=\"\", is_user=True)\n",
    "messages_empty = chat_history.get_messages(chat_id_empty)\n",
    "print(f\"Empty Messages: {messages_empty}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-existent chat ID\n",
    "messages_non_existent = chat_history.get_messages(\"non_existent_id\")\n",
    "print(f\"Messages for non-existent chat ID: {messages_non_existent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Cleanup\n",
    "\n",
    "# Delete chat\n",
    "chat_history.delete_chat(chat_id)\n",
    "print(f\"Deleted Chat ID: {chat_id}\")\n",
    "\n",
    "# Archive and Unpin Chats\n",
    "chat_history.archive_chat(chat_id)\n",
    "chat_history.pin_chat(chat_id)\n",
    "chat_history.unpin_chat(chat_id)\n",
    "print(\"Archived and unpinned chat.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Chain Of Thoughts in SQLQuery Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "## Chain Of Thoughts and CRAG\n",
    "class SQLExpert:\n",
    "    def __init__(self, llm):\n",
    "        llm = llm\n",
    "\n",
    "    def generate_query(self, user_query: str, dialect: str, table_info: str, chat_history: str = '') -> str:\n",
    "        relevant_tables = identify_relevant_tables(user_query, table_info, chat_history)\n",
    "        query_steps = identify_query_steps(user_query, relevant_tables, chat_history)\n",
    "        sql_query = generate_sql(user_query, dialect, relevant_tables, query_steps, chat_history)\n",
    "        if sql_query.lower().strip() != \"invalid user query - not related to the database\":\n",
    "            sql_query = correct_query(sql_query, dialect, table_info, user_query, chat_history)\n",
    "        return sql_query\n",
    "\n",
    "    def identify_relevant_tables(self, user_query: str, table_info: str, chat_history: str) -> List[str]:\n",
    "        template = \"\"\"Given the user query and available tables, identify the list of tables that are relevant to answer the query.\n",
    "        Only include tables that are directly related to the query. Do not include any tables that are not mentioned in the table information.\n",
    "\n",
    "        User Query: {user_query}\n",
    "        Table Information: {table_info}\n",
    "        Chat History: {chat_history}\n",
    "\n",
    "        Relevant Tables (comma-separated list):\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        chain = prompt | llm\n",
    "        result = chain.invoke({\n",
    "            \"user_query\": user_query,\n",
    "            \"table_info\": table_info,\n",
    "            \"chat_history\": chat_history\n",
    "        }).content.strip()\n",
    "        return [table.strip() for table in result.split(',')]\n",
    "\n",
    "    def identify_query_steps(self, user_query: str, relevant_tables: List[str], chat_history: str) -> List[str]:\n",
    "        template = \"\"\"Given the user query and relevant tables, identify the steps that should be taken to answer the query.\n",
    "        Provide a numbered list of high-level steps, focusing on the logical flow of data manipulation and analysis.\n",
    "\n",
    "        User Query: {user_query}\n",
    "        Relevant Tables: {relevant_tables}\n",
    "        Chat History: {chat_history}\n",
    "\n",
    "        Query Steps:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        chain = prompt | llm\n",
    "        result = chain.invoke({\n",
    "            \"user_query\": user_query,\n",
    "            \"relevant_tables\": \", \".join(relevant_tables),\n",
    "            \"chat_history\": chat_history\n",
    "        }).content.strip()\n",
    "        return [step.strip() for step in result.split('\\n') if step.strip()]\n",
    "\n",
    "    def generate_sql(self, user_query: str, dialect: str, relevant_tables: List[str], query_steps: List[str], chat_history: str) -> str:\n",
    "        template = \"\"\"Given the user query, relevant tables, and query steps, generate ONLY a syntactically correct {dialect} SQL query.\n",
    "        Follow these rules:\n",
    "        - Do not assume any table or columns that are not mentioned in the relevant tables.\n",
    "        - Do not include any CREATE, DELETE, UPDATE, or ALTER statements.\n",
    "        - Use Common Table Expressions (CTEs) for data manipulation instead of subqueries.\n",
    "        - Never use * in the SELECT statement. Always specify the columns you want to retrieve, even in CTEs.\n",
    "        - Use GROUP BY instead of DISTINCT where applicable.\n",
    "        - Do not include any LIMIT or OFFSET clauses unless the user query explicitly requires it.\n",
    "        - Use the information from the chat history if it adds context or relevant details to the current question.\n",
    "        - If the query cannot be generated, just return one sentence: \"Invalid User Query - Not related to the Database.\".\n",
    "        - Do not include any explanations, comments, or additional text. Return ONLY the SQL query.\n",
    "\n",
    "        User Query: {user_query}\n",
    "        Dialect: {dialect}\n",
    "        Relevant Tables: {relevant_tables}\n",
    "        Query Steps: {query_steps}\n",
    "        Chat History: {chat_history}\n",
    "\n",
    "        SQL Query:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        chain = prompt | llm\n",
    "        sql_query = chain.invoke({\n",
    "            \"user_query\": user_query,\n",
    "            \"dialect\": dialect,\n",
    "            \"relevant_tables\": \", \".join(relevant_tables),\n",
    "            \"query_steps\": \"\\n\".join(query_steps),\n",
    "            \"chat_history\": chat_history\n",
    "        }).content.strip()\n",
    "\n",
    "        return sql_query\n",
    "\n",
    "\n",
    "## Update\n",
    "\n",
    "    def correct_query(self, sql_query: str, dialect: str, table_info: str, user_query: str, chat_history: str) -> str:\n",
    "        corrective_template = \"\"\"You are a SQL expert. Given a generated SQL query, evaluate it to ensure it adheres to the following criteria:\n",
    "        - Does not Assume any table or columns that are not mentioned.\n",
    "        - Does not include any CREATE, DELETE, UPDATE, or ALTER statements in your responses.\n",
    "        - Using Common Table Expressions (CTEs) for data manipulation instead of subqueries.\n",
    "        - No use of * in the SELECT statement. The columns wanted are always specified to retrieve. Even while querying from Common Table Expressions.\n",
    "        - Group by is used instead of distinct where applicable.\n",
    "        - This is a syntactically correct {dialect} query to run using Only the tables and columns that are mentined in the database.\n",
    "\n",
    "        Do not include an improved SQL Query and do not write or suggest any code. Just provide feedback on the existing query and suggest improvements.\n",
    "        If the query is already good, your response should just be one word: \"All good\". Otherwise, provide feedback and suggest improvements. \n",
    "        If the query can not be generated, your response should just be one sentence: \"Invalid User Query - Not related to the Database\".\n",
    "        Do not include an improved query.\n",
    "\n",
    "        Table Info: {table_info}\n",
    "        Chat History: {chat_history}\n",
    "        User Query: {user_query}\n",
    "        Generated SQL Query: {sql_query}\n",
    "        Correction:\n",
    "        \"\"\"\n",
    "        corrective_prompt = PromptTemplate.from_template(corrective_template)\n",
    "        corrective_chain = corrective_prompt | self.llm\n",
    "        correction_result = corrective_chain.invoke({\n",
    "            \"user_query\": user_query,\n",
    "            \"sql_query\": sql_query,\n",
    "            \"dialect\": dialect,\n",
    "            \"table_info\": table_info,\n",
    "            \"chat_history\": chat_history\n",
    "        }).content.strip()\n",
    "\n",
    "        if correction_result.lower().strip() != \"all good\":\n",
    "            sql_query = self.adjust_query(sql_query, dialect, table_info, user_query, correction_result, chat_history)\n",
    "\n",
    "        return sql_query\n",
    "\n",
    "    def adjust_query(self, sql_query: str, dialect: str, table_info: str, user_query: str, correction: str, chat_history: str) -> str:\n",
    "        adjustment_template = \"\"\"You are a SQL expert. Given a generated SQL query, correction feedback, dialect, table information, and user query, adjust the query to make it more accurate and better answer the user query.\n",
    "        If the query can not be generated, your response should just be one sentence: \"Invalid User Query - Not related to the Database\".\n",
    "        If no changes are required, return the original query as is.\n",
    "        If changes are required, follow these rules:\n",
    "        - Do not Assume any table or columns that are not mentioned.\n",
    "        - Do not include any CREATE, DELETE, UPDATE, or ALTER statements in your responses.\n",
    "        - Use Common Table Expressions (CTEs) for data manipulation instead of subqueries.\n",
    "        - Never use * in the SELECT statement. Always specify the columns you want to retrieve. Even if you are querying from Common Table Expressions.\n",
    "        - Use group by instead of distinct where applicable.\n",
    "        - Do not include any LIMIT, or OFFSET clauses in your responses unless the user query requires it.\n",
    "        - Use the information from the chat history if they add context or relevant details to the current question. Focus primarily on the most recent and relevant questions. If the previous questions do not add any context, just focus on the current question.\n",
    "\n",
    "        Dialect: {dialect}\n",
    "        Table Info: {table_info}\n",
    "        User Query: {user_query}\n",
    "        Chat History: {chat_history}\n",
    "        Generated SQL Query: {sql_query}\n",
    "        Correction Feedback: {correction}\n",
    "        Adjusted SQL Query:\n",
    "        \"\"\"\n",
    "        adjustment_prompt = PromptTemplate.from_template(adjustment_template)\n",
    "        adjustment_chain = adjustment_prompt | self.llm\n",
    "        adjusted_query = adjustment_chain.invoke({\n",
    "            \"user_query\": user_query,\n",
    "            \"sql_query\": sql_query,\n",
    "            \"dialect\": dialect,\n",
    "            \"table_info\": table_info,\n",
    "            \"correction\": correction,\n",
    "            \"chat_history\": chat_history\n",
    "        }).content.strip()\n",
    "\n",
    "        return adjusted_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Stuff.Agent_Helpers import load_elecdata_postgres, clean_sql_query, SQLCoder, DDLCommandException\n",
    "from AI_Stuff.CustomAgents import ResponseSummarizer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "db = load_elecdata_postgres()\n",
    "dialect = db.dialect\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")\n",
    "schema_info = db.get_table_info()\n",
    "sql_coder_agent = SQLExpert(llm = llm)\n",
    "sql_query_tool = SQLCoder(db=db)\n",
    "response_summarizer_agent = ResponseSummarizer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Workflow(user_query: str):\n",
    "    sql_query = sql_coder_agent.generate_query(\n",
    "        user_query = user_query\n",
    "        , dialect='postgres'\n",
    "        , table_info=schema_info\n",
    "        , chat_history=''\n",
    "    )\n",
    "    sql_query = clean_sql_query(sql_query)\n",
    "    if \"CREATE\" in sql_query or \"DELETE\" in sql_query or \"UPDATE\" in sql_query or \"ALTER\" in sql_query:\n",
    "        raise DDLCommandException\n",
    "    elif sql_query.lower().strip() == \"invalid user query - not related to the database.\":\n",
    "        return sql_query\n",
    "    else:\n",
    "        data = sql_query_tool.execute_query(sql_query)\n",
    "        response = response_summarizer_agent.summarize(user_query=user_query, dataframe=data)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"Analyze the distribution of vacancies across states. What observations can you make?\"\n",
    "    ,\"What patterns do you notice in the transfer of votes between candidates?\"\n",
    "    ,\"Calculate the total votes received and the percentage of total votes for each candidate.\"\n",
    "    ,\"Identify any correlations between primary votes and the state or location of voting.\"\n",
    "    ,\"Compare the performance of candidates across different voting methods (ordinary, postal, pre-poll, etc.). What trends do you observe?\"\n",
    "    ,\"How does the number of rounds vary between different pools, and what might this indicate about the competitiveness of the elections?\"\n",
    "    ,\"Analyze how ballot position correlates with the number of primary votes received. What conclusions can you draw?\"\n",
    "    ,\"Perform a comprehensive analysis of voting patterns and party performance across different elections and regions. Identify any notable trends or shifts in voter behavior.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for question in questions[1:3]:\n",
    "    res = Workflow(user_query=question)\n",
    "    print(f\"Question: {question}\\nResponse: {res}\\n\")\n",
    "    print('---'*20)\n",
    "    time.sleep(180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiDB SQL Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Failed Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent_Helpers 24-Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for loadPostgresDatabase function\n",
    "\n",
    "from AI_Stuff.Agent_Helpers2 import *\n",
    "import os\n",
    "\n",
    "db_name = os.environ.get(\"POLIMAP_DB_NAME\")\n",
    "try:\n",
    "    # Test loading a database with valid input\n",
    "    db = loadPostgresDatabase(db_name)\n",
    "    print(\"Database loaded successfully:\", db)\n",
    "except ValueError as e:\n",
    "    print(\"ValueError:\", e)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "\n",
    "\n",
    "db_name = os.environ.get(\"ELECDATA_DB_NAME\")\n",
    "try:\n",
    "    # Test loading a database with valid input\n",
    "    db = loadPostgresDatabase(db_name)\n",
    "    print(\"Database loaded successfully:\", db)\n",
    "except ValueError as e:\n",
    "    print(\"ValueError:\", e)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Test for `loadLLM`\n",
    "try:\n",
    "    llm_gpt = loadLLM(llmName='gpt')\n",
    "    llm_claude = loadLLM(llmName='claude')\n",
    "    print(\"loadLLM: Success\")\n",
    "except ValueError as e:\n",
    "    print(f\"loadLLM: Failed with ValueError - {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"loadLLM: Failed with Exception - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Test for `webSearch`\n",
    "try:\n",
    "    result = webSearch(\"OpenAI GPT-4\")\n",
    "    print(f\"webSearch: Success - {result[:100]}...\")  # Print only the first 100 characters\n",
    "except Exception as e:\n",
    "    print(f\"webSearch: Failed with Exception - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Test for `cleanSqlQuery`\n",
    "test_query_1 = \"### Adjusted SQL Query: SELECT * FROM users\"\n",
    "test_query_2 = \"sql SELECT * FROM orders SQLQuery: SELECT id, order_date FROM orders\"\n",
    "test_query_3 = \"SELECT id FROM customers WHERE name = 'John Doe'\"\n",
    "\n",
    "cleaned_query_1 = cleanSqlQuery(test_query_1)\n",
    "cleaned_query_2 = cleanSqlQuery(test_query_2)\n",
    "cleaned_query_3 = cleanSqlQuery(test_query_3)\n",
    "\n",
    "print(f\"cleanSqlQuery Test 1: {cleaned_query_1}\")\n",
    "print(f\"cleanSqlQuery Test 2: {cleaned_query_2}\")\n",
    "print(f\"cleanSqlQuery Test 3: {cleaned_query_3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from fpdf import FPDF\n",
    "import tempfile\n",
    "from aiStuff.agentHelpers import ChatHistory\n",
    "chat_history = ChatHistory(userId=\"test_user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding Functionality\n",
    "chat_id_1 = chat_history.addMessage(None, \"New Message Chat ID 1\")\n",
    "chat_id_2 = chat_history.addMessage(None, \"New Message Chat ID 2\")\n",
    "chat_history.addMessage(chat_id_1, \"chatid one append 1\")\n",
    "chat_history.addMessage(chat_id_2, \"chatid two append 1\")\n",
    "chat_history.addMessage(chat_id_1, \"chatid one append 2\")\n",
    "chat_history.addMessage(chat_id_2, \"chatid two append 2\")\n",
    "\n",
    "print(f\"chat id 1: {chat_id_1}, chat id 2: {chat_id_2}\")\n",
    "\n",
    "## Retrieving Functionality\n",
    "all_chats = chat_history.getAllChats()\n",
    "print(\"All chats:\")\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Retrieving specific chat\n",
    "messages = chat_history.getMessages(chat_id_1)\n",
    "print(\"\\nMessages for chat_id_1:\")\n",
    "for message in messages:\n",
    "    print(message)\n",
    "    msg_id = message['messageId']\n",
    "\n",
    "## Retrieving specific message\n",
    "msg = chat_history.getMessage(chat_id_1, msg_id)\n",
    "print(f\"\\nRetrieved message: {msg}\")\n",
    "\n",
    "## Retrieving most recent chats\n",
    "recent_chats = chat_history.getRecentMessages(chat_id_1)\n",
    "print(\"\\nMost recent chats:\")\n",
    "for chat in recent_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Pinning Unpinning\n",
    "chat_history.pinChat(chat_id_1)\n",
    "print(\"\\nChat_id_1 pinned.\")\n",
    "all_chats = chat_history.getAllChats()\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "chat_history.unpinChat(chat_id_1)\n",
    "print(\"\\nChat_id_1 unpinned.\")\n",
    "all_chats = chat_history.getAllChats()\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Archiving and Unarchiving\n",
    "chat_history.archiveChat(chat_id_2)\n",
    "print(\"\\nChat_id_2 archived.\")\n",
    "all_chats = chat_history.getAllChats()\n",
    "print(\"All chats:\")\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "\n",
    "chat_history.unarchiveChat(chat_id_2)\n",
    "print(\"\\nChat_id_2 unarchived.\")\n",
    "all_chats = chat_history.getAllChats()\n",
    "print(\"All chats:\")\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Title Update\n",
    "chat_history.updateChatTitle(chat_id_1, \"Updated Chat Title\")\n",
    "print(\"\\nChat_id_1 title updated.\")\n",
    "all_chats = chat_history.getAllChats()\n",
    "print(\"All chats:\")\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Test Search\n",
    "search_results = chat_history.searchChats(\"append\")\n",
    "print(\"\\nSearch results for 'append':\")\n",
    "for result in search_results:\n",
    "    print(result)\n",
    "\n",
    "## CSV Upload\n",
    "csv_file = b\"col1,col2\\nval1,val2\"\n",
    "file_id = chat_history.uploadDoc(chat_id_1, csv_file, \"test.csv\", \"csv\")\n",
    "print(f\"\\nUploaded CSV document ID: {file_id}\")\n",
    "\n",
    "## PDF Upload\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "pdf.cell(200, 10, txt=\"Hello World!\", ln=True, align=\"C\")\n",
    "with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_file:\n",
    "    pdf.output(temp_file.name)\n",
    "    temp_file.seek(0)\n",
    "    pdf_file = temp_file.read()\n",
    "file_id = chat_history.uploadDoc(chat_id_1, pdf_file, \"valid_test.pdf\", \"pdf\")\n",
    "print(f\"U\\nploaded Valid PDF Doc ID: {file_id}\")\n",
    "\n",
    "## text upload\n",
    "text_file = b\"Hello World!\"\n",
    "file_id = chat_history.uploadDoc(chat_id_1, text_file, \"test.txt\", \"txt\")\n",
    "print(f\"\\nUploaded Text Doc ID: {file_id}\")\n",
    "\n",
    "## Get documents context\n",
    "doc_context = chat_history.getDocumentsContext(chat_id_1)\n",
    "print(f\"\\nDocument Context: {doc_context}\")\n",
    "\n",
    "## Edge Case Invalid document type\n",
    "try:\n",
    "    chat_history.uploadDoc(chat_id_1, csv_file, \"test.txt\", \"txt\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "## Test Edit Message Functionality\n",
    "chat_history.addMessage(chat_id_1, \"chatid one append 3\")\n",
    "chat_history.addMessage(chat_id_1, \"chatid one append 4\")\n",
    "messages = chat_history.getMessages(chat_id_1)\n",
    "print(\"\\nMessages for chat_id_1:\")\n",
    "for message in messages:\n",
    "    print(message)\n",
    "third_message_id = messages[2]['messageId']\n",
    "chat_history.updateMessage(chat_id_1, third_message_id, \"Updated content for third message\")\n",
    "messages = chat_history.getMessages(chat_id_1)\n",
    "print(\"\\nUpdated messages for chat_id_1:\")\n",
    "for message in messages:\n",
    "    print(message)\n",
    "\n",
    "\n",
    "## Test Delete\n",
    "chat_history.deleteChat(chat_id_2)\n",
    "print(\"\\nChat_id_2 deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing New Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aiStuff.workflows import ElecDataWorkflow\n",
    "# workflow = ElecDataWorkflow()\n",
    "\n",
    "# res = workflow.processUserQuery(userQuery=\"HI\")\n",
    "# print(res)\n",
    "\n",
    "# res = workflow.processUserQuery(userQuery=\"I feel like I have the prettiest girlfriend in the world!\")\n",
    "# print(res)\n",
    "\n",
    "# res = workflow.processUserQuery(userQuery=\"How many votes did each party get in 2022?\")\n",
    "# print(res)\n",
    "\n",
    "# res = workflow.processUserQuery(userQuery=\"How can the pretty use this?\")\n",
    "# print(res)\n",
    "\n",
    "# res = workflow.processUserQuery(userQuery=\"I just want to knw about top 10 parties.\")\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Metadata and tablenames --> Get relevent tables --> Get TableInfo --> Continue: Does Not work due to lack of FK information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# from typing import List, Dict, Any\n",
    "# from langchain_core.prompts import PromptTemplate\n",
    "# from langchain.base_language import BaseLanguageModel\n",
    "# from aiStuff.agentHelpers import loadPostgresDatabase, cleanSqlQuery, QuerySQLTool, InvalidUserQueryException, NoDataFoundException\n",
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# # logger = logging.getLogger(__name__)\n",
    "\n",
    "# class ElecDataWorkflow2:\n",
    "#     def __init__(self, llm: BaseLanguageModel, dbName: str = 'JL'):\n",
    "#         self.llm = llm\n",
    "#         self.dbName = dbName\n",
    "#         self.sqlQueryTool = QuerySQLTool(dbName=self.dbName)\n",
    "#         self._setTableInfo()\n",
    "#         self._setDialect()\n",
    "#         self.MAX_RETRIES = 3\n",
    "\n",
    "#     def _setTableInfo(self):\n",
    "#         with loadPostgresDatabase(self.dbName) as db:\n",
    "#             self.tableInfo = db.get_table_info()\n",
    "\n",
    "#     def _setDialect(self):\n",
    "#         with loadPostgresDatabase(self.dbName) as db:\n",
    "#             self.dialect = db.dialect\n",
    "\n",
    "#     def _selectPotentialTables(self, userQuery: str) -> List[str]:\n",
    "#         template = \"\"\"\n",
    "#         Given the following user query and available tables, select the most relevant tables that might be needed to answer the query.\n",
    "        \n",
    "#         User Query: {userQuery}\n",
    "        \n",
    "#         Available Tables:\n",
    "#         {tableInfo}\n",
    "        \n",
    "#         Return a comma-separated list of table names, without any additional explanation.\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate.from_template(template)\n",
    "#         chain = prompt | self.llm\n",
    "#         result = chain.invoke({\"userQuery\": userQuery, \"tableInfo\": self.tableInfo})\n",
    "#         return [table.strip() for table in result.content.split(',')]\n",
    "\n",
    "#     def _determineJoinConditions(self, tables: List[str]) -> Dict[str, str]:\n",
    "#         template = \"\"\"\n",
    "#         Given the following target tables, determine the appropriate join conditions between them. (JOIN ONLY AMONGST TARGET TABLES)\n",
    "        \n",
    "#         Target Tables: {tables}\n",
    "        \n",
    "#         Table Information:\n",
    "#         {tableInfo}\n",
    "        \n",
    "#         Return a JSON object where the keys are pairs of table names (e.g., \"table1__table2\") and the values are the join conditions.\n",
    "#         Just return a json object that can be loaded into json directly and nothing else.\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate.from_template(template)\n",
    "#         chain = prompt | self.llm\n",
    "#         result = chain.invoke({\"tables\": ', '.join(tables), \"tableInfo\": self.tableInfo}).content\n",
    "#         result = result.replace('`', '').replace('json', '')\n",
    "#         return json.loads(result)\n",
    "\n",
    "#     def _selectFilteringColumns(self, tables: List[str], userQuery: str) -> List[str]:\n",
    "#         template = \"\"\"\n",
    "#         Given the following user query and selected tables, determine which columns should be used for filtering the results.\n",
    "        \n",
    "#         User Query: {userQuery}\n",
    "#         Selected Tables: {tables}\n",
    "        \n",
    "#         Table Information:\n",
    "#         {tableInfo}\n",
    "        \n",
    "#         Return a comma-separated list of column names (including table names, e.g., \"table.column\"), without any additional explanation.\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate.from_template(template)\n",
    "#         chain = prompt | self.llm\n",
    "#         result = chain.invoke({\"userQuery\": userQuery, \"tables\": ', '.join(tables), \"tableInfo\": self.tableInfo})\n",
    "#         return [col.strip() for col in result.content.split(',')]\n",
    "\n",
    "#     def _executeQueryWithRetry(self, queryFunc, *args, **kwargs):\n",
    "#         for attempt in range(self.MAX_RETRIES):\n",
    "#             try:\n",
    "#                 query = queryFunc(*args, **kwargs)\n",
    "#                 result = self.sqlQueryTool.executeQuery(query)\n",
    "#                 return result\n",
    "#             except Exception as e:\n",
    "#                 # logger.warning(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "#                 print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "#                 if attempt == self.MAX_RETRIES - 1:\n",
    "#                     raise\n",
    "#                 # Provide feedback to the AI for query refinement\n",
    "#                 kwargs['error_feedback'] = str(e)\n",
    "        \n",
    "#         raise Exception(f\"Failed to execute query after {self.MAX_RETRIES} attempts\")\n",
    "\n",
    "#     def _generateDistinctQuery(self, tables: List[str], joinConditions: Dict[str, str], filteringColumns: List[str], error_feedback: str = \"\") -> str:\n",
    "#         template = \"\"\"\n",
    "#         Generate a SQL query to select distinct values from the specified columns and tables.\n",
    "#         Use the provided join conditions to connect the tables.\n",
    "        \n",
    "#         Tables: {tables}\n",
    "#         Join Conditions: {joinConditions}\n",
    "#         Filtering Columns: {filteringColumns}\n",
    "        \n",
    "#         Table Information:\n",
    "#         {tableInfo}\n",
    "        \n",
    "#         Error Feedback: {error_feedback}\n",
    "        \n",
    "#         Rules:\n",
    "#         1. Use SELECT DISTINCT for the specified filtering columns only.\n",
    "#         2. Include only the tables necessary for the filtering columns in the FROM and JOIN clauses.\n",
    "#         3. Use the provided join conditions to connect tables, but only include joins necessary for the filtering columns.\n",
    "#         4. Do not include any WHERE clauses or additional filtering.\n",
    "#         5. Use table aliases if necessary for clarity.\n",
    "#         6. Ensure the query is compatible with PostgreSQL.\n",
    "#         7. If error feedback is provided, adjust the query to address the issue.\n",
    "#         8. Do not include any aggregations or GROUP BY clauses.\n",
    "#         9. The goal is to get unique combinations of values in the filtering columns, not to perform any calculations.\n",
    "\n",
    "#         Return only the SQL query without any additional explanation.\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate.from_template(template)\n",
    "#         chain = prompt | self.llm\n",
    "#         result = chain.invoke({\n",
    "#             \"tables\": ', '.join(tables),\n",
    "#             \"joinConditions\": json.dumps(joinConditions),\n",
    "#             \"filteringColumns\": ', '.join(filteringColumns),\n",
    "#             \"tableInfo\": self.tableInfo,\n",
    "#             \"error_feedback\": error_feedback\n",
    "#         })\n",
    "#         return cleanSqlQuery(result.content)\n",
    "\n",
    "#     def _determineFilterValues(self, distinctQueryResult: pd.DataFrame, userQuery: str) -> Dict[str, Any]:\n",
    "#         template = \"\"\"\n",
    "#         Given the following user query and distinct values for potential filtering columns, determine the appropriate filter values to use in the SQL query.\n",
    "        \n",
    "#         User Query: {userQuery}\n",
    "        \n",
    "#         Distinct Values:\n",
    "#         {distinctValues}\n",
    "        \n",
    "#         Return a JSON object where the keys are column names and the values are the filter values to use. If a column should not be used for filtering, omit it from the result.\n",
    "#         Just return a json object that can be loaded into json directly and nothing else.\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate.from_template(template)\n",
    "#         chain = prompt | self.llm\n",
    "#         result = chain.invoke({\"userQuery\": userQuery, \"distinctValues\": distinctQueryResult.to_json(orient='records')}).content\n",
    "#         result = result.replace('`', '').replace('json', '')\n",
    "#         return json.loads(result)\n",
    "\n",
    "#     def _generateFinalQuery(self, tables: List[str], joinConditions: Dict[str, str], filteringColumns: List[str], filterValues: Dict[str, Any], userQuery: str, error_feedback: str = \"\") -> str:\n",
    "#         template = \"\"\"\n",
    "#         Generate a SQL query based on the following information:\n",
    "        \n",
    "#         User Query: {userQuery}\n",
    "#         Tables: {tables}\n",
    "#         Join Conditions: {joinConditions}\n",
    "#         Filtering Columns: {filteringColumns}\n",
    "#         Filter Values: {filterValues}\n",
    "        \n",
    "#         Table Information:\n",
    "#         {tableInfo}\n",
    "        \n",
    "#         Error Feedback: {error_feedback}\n",
    "        \n",
    "#         Rules:\n",
    "#         1. Generate a complete SQL query that answers the user's question.\n",
    "#         2. Include appropriate SELECT, FROM, JOIN, and WHERE clauses.\n",
    "#         3. Use the provided join conditions to connect tables.\n",
    "#         4. Use the filtering columns and filter values to create appropriate WHERE conditions.\n",
    "#         5. Do not use subqueries; use CTEs if necessary.\n",
    "#         6. Ensure the query is compatible with PostgreSQL.\n",
    "#         7. Use table aliases if necessary for clarity.\n",
    "#         8. If error feedback is provided, adjust the query to address the issue.\n",
    "#         9. ONLY use column names that are explicitly mentioned in the Table Information.\n",
    "#         10. Do not hallucinate or invent column names.\n",
    "\n",
    "#         Return only the SQL query without any additional explanation.\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate.from_template(template)\n",
    "#         chain = prompt | self.llm\n",
    "#         result = chain.invoke({\n",
    "#             \"userQuery\": userQuery,\n",
    "#             \"tables\": ', '.join(tables),\n",
    "#             \"joinConditions\": json.dumps(joinConditions),\n",
    "#             \"filteringColumns\": ', '.join(filteringColumns),\n",
    "#             \"filterValues\": json.dumps(filterValues),\n",
    "#             \"tableInfo\": self.tableInfo,\n",
    "#             \"error_feedback\": error_feedback\n",
    "#         })\n",
    "#         query = cleanSqlQuery(result.content)\n",
    "        \n",
    "#         # Implement CRAG (Constrained Retrieval Augmented Generation)\n",
    "#         crag_template = \"\"\"\n",
    "#         You are a SQL expert. Review the following SQL query and ensure it follows all the rules and is runnable. \n",
    "#         Do not hallucinate on table names, column names, or join conditions. Only use information provided in the Table Information.\n",
    "\n",
    "#         SQL Query:\n",
    "#         {query}\n",
    "\n",
    "#         Table Information:\n",
    "#         {tableInfo}\n",
    "\n",
    "#         Rules to check:\n",
    "#         1. All table names used in the query exist in the Table Information.\n",
    "#         2. All column names used in the query exist in their respective tables as per the Table Information.\n",
    "#         3. Join conditions use existing tables and columns.\n",
    "#         4. The query structure is valid PostgreSQL syntax.\n",
    "#         5. No subqueries are used (CTEs are allowed).\n",
    "#         6. The query addresses the User Query without adding extraneous information.\n",
    "\n",
    "#         User Query: {userQuery}\n",
    "\n",
    "#         If the query violates any rules or is not runnable, provide a corrected version. \n",
    "#         If the query is correct and follows all rules, return it as is.\n",
    "\n",
    "#         Corrected SQL Query:\n",
    "#         \"\"\"\n",
    "#         crag_prompt = PromptTemplate.from_template(crag_template)\n",
    "#         crag_chain = crag_prompt | self.llm\n",
    "#         crag_result = crag_chain.invoke({\n",
    "#             \"query\": query,\n",
    "#             \"tableInfo\": self.tableInfo,\n",
    "#             \"userQuery\": userQuery\n",
    "#         })\n",
    "#         return cleanSqlQuery(crag_result.content)\n",
    "\n",
    "#     def processUserQuery(self, userQuery: str) -> str:\n",
    "#         try:\n",
    "#             potentialTables = self._selectPotentialTables(userQuery)\n",
    "#             joinConditions = self._determineJoinConditions(potentialTables)\n",
    "#             filteringColumns = self._selectFilteringColumns(potentialTables, userQuery)\n",
    "            \n",
    "#             distinctQueryResult = self._executeQueryWithRetry(\n",
    "#                 self._generateDistinctQuery,\n",
    "#                 potentialTables,\n",
    "#                 joinConditions,\n",
    "#                 filteringColumns\n",
    "#             )\n",
    "            \n",
    "#             filterValues = self._determineFilterValues(distinctQueryResult, userQuery)\n",
    "            \n",
    "#             finalQueryResult = self._executeQueryWithRetry(\n",
    "#                 self._generateFinalQuery,\n",
    "#                 potentialTables,\n",
    "#                 joinConditions,\n",
    "#                 filteringColumns,\n",
    "#                 filterValues,\n",
    "#                 userQuery\n",
    "#             )\n",
    "            \n",
    "#             return self._summarizeResult(finalQueryResult, userQuery)\n",
    "#         except InvalidUserQueryException as e:\n",
    "#             return str(e)\n",
    "#         except NoDataFoundException as e:\n",
    "#             return str(e)\n",
    "#         except Exception as e:\n",
    "#             return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "#     def _summarizeResult(self, queryResult: pd.DataFrame, userQuery: str) -> str:\n",
    "#         template = \"\"\"\n",
    "#         Summarize the following query result in response to the user's question. Provide key insights and relevant statistics.\n",
    "        \n",
    "#         User Query: {userQuery}\n",
    "        \n",
    "#         Query Result:\n",
    "#         {queryResult}\n",
    "        \n",
    "#         Summary:\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate.from_template(template)\n",
    "#         chain = prompt | self.llm\n",
    "#         result = chain.invoke({\"userQuery\": userQuery, \"queryResult\": queryResult.to_json(orient='records')})\n",
    "#         return result.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiStuff.workflows import ElecDataWorkflow\n",
    "workflow = ElecDataWorkflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of votes the Greens party received in the last elections is not available.\n"
     ]
    }
   ],
   "source": [
    "res = workflow.processUserQuery(userQuery=\"What percent of votes did the greens party got in the last elections?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# API base URL\n",
    "BASE_URL = \"http://127.0.0.1:8000/api\"\n",
    "\n",
    "def test_handle_send(content, user_id, chat_id=None):\n",
    "    url = f\"{BASE_URL}/messages/send\"\n",
    "    data = {\"content\": content, \"chatId\": chat_id}\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.post(url, json=data, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_get_latest_messages(chat_id, user_id, limit=2):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/latest\"\n",
    "    params = {\"userId\": user_id, \"limit\": limit}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_fetch_messages(chat_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/messages\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_fetch_chat_history(user_id):\n",
    "    url = f\"{BASE_URL}/chats/all\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_pin_chat(chat_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/pin\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.put(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_unpin_chat(chat_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/unpin\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.put(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_search(term, user_id):\n",
    "    url = f\"{BASE_URL}/chats/search\"\n",
    "    params = {\"term\": term, \"userId\": user_id}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_archive_chat(chat_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/archive\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.put(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_unarchive_chat(chat_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/unarchive\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.put(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_update_chat_title(chat_id, new_title, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/title\"\n",
    "    params = {\"userId\": user_id, \"newTitle\": new_title}\n",
    "    response = requests.put(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_copy_message(chat_id, message_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/messages/{message_id}\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_update_message(chat_id, message_id, new_content, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/messages/{message_id}\"\n",
    "    params = {\"userId\": user_id, \"newContent\": new_content}\n",
    "    response = requests.put(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_delete_chat(chat_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/delete\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.delete(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_upload_file(chat_id, user_id, file_path):\n",
    "    url = f\"{BASE_URL}/{chat_id}/upload\"\n",
    "    params = {\"userId\": user_id}\n",
    "    files = {'file': open(file_path, 'rb')}\n",
    "    response = requests.post(url, params=params, files=files)\n",
    "    return response.json()\n",
    "\n",
    "def test_update_group_status(chatId, user_id, group_name, group_color):\n",
    "    url = f\"{BASE_URL}/chats/{chatId}/group\"\n",
    "    params = {\"userId\": user_id}\n",
    "    data = {\"groupName\": group_name, \"groupColor\": group_color}\n",
    "    response = requests.put(url, params=params, json=data)\n",
    "    return response.json()\n",
    "\n",
    "# Test cases\n",
    "user_id = 'Test_User_04_Sep'\n",
    "\n",
    "print(\"Testing addMessage for a new user...\")\n",
    "result = test_handle_send(\"How many votes did each party get in 2022\", user_id=user_id)\n",
    "print(result)\n",
    "chat_id = result['chatId']\n",
    "\n",
    "print(\"Testing addMessage for the new chat...\")\n",
    "test_handle_send(\"Give me result for top 10 parties.\", chat_id=chat_id, user_id=user_id)\n",
    "\n",
    "print(\"Testing get latest messages...\")\n",
    "latest_msgs = test_get_latest_messages(chat_id, user_id)\n",
    "print(latest_msgs)\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing fetch messages...\")\n",
    "msgs = test_fetch_messages(chat_id, user_id)\n",
    "message_id = msgs[2]['messageId']\n",
    "print(msgs)\n",
    "print(\"*--\"*20)\n",
    "\n",
    "new_title = 'New Chat Title'\n",
    "new_content = 'Just Give me names of top 3 parties.'\n",
    "\n",
    "print(\"Testing fetch chat history...\")\n",
    "print(test_fetch_chat_history(user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing handle pin chat...\")\n",
    "print(test_handle_pin_chat(chat_id, user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing handle unpin chat...\")\n",
    "print(test_handle_unpin_chat(chat_id, user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing handle search...\")\n",
    "print(test_handle_search('party', user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing handle archive chat...\")\n",
    "print(test_handle_archive_chat(chat_id, user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing handle unarchive chat...\")\n",
    "print(test_handle_unarchive_chat(chat_id, user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing handle update chat title...\")\n",
    "print(test_handle_update_chat_title(chat_id, new_title, user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing copy message...\")\n",
    "print(test_copy_message(chat_id, message_id, user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing handle update message...\")\n",
    "print(test_handle_update_message(chat_id, message_id, new_content, user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "# New tests for file upload and group status update\n",
    "print(\"Testing file upload...\")\n",
    "file_path = 'test_file.txt'  # Make sure this file exists in the same directory\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write(\"This is a test file for upload.\")\n",
    "print(test_upload_file(chat_id, user_id, file_path))\n",
    "os.remove(file_path)  # Clean up the test file\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing update group status...\")\n",
    "print(test_update_group_status(chat_id, user_id, \"TestGroup\", \"blue\"))\n",
    "print(\"*--\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing handle delete chat...\")\n",
    "print(test_handle_delete_chat(chat_id, user_id))\n",
    "print(\"*--\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Workflow unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiStuff.agentHelpers import loadPostgresDatabase, cleanSqlQuery, cleanSummaryResponse, QuerySQLTool, InvalidUserQueryException, NoDataFoundException, loadLLM\n",
    "from aiStuff.customAgents import SqlExpert, ResponseSummarizer\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "load_dotenv(dotenv_path='./resources/.ENV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qn1 = 'How many votes did each party get in 2022'\n",
    "qn2 = 'Give me result for top 10 parties.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbName = os.getenv(\"ELECDATA_DB_NAME\")\n",
    "llm = loadLLM()\n",
    "sqlCoderAgent = SqlExpert(llm=llm)\n",
    "sqlQueryTool = QuerySQLTool(dbName=dbName)\n",
    "responseSummarizerAgent = ResponseSummarizer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableInfo = None\n",
    "with loadPostgresDatabase(dbName) as db:\n",
    "    tableInfo = db.get_table_info()\n",
    "\n",
    "def _generateQuery(userQuery: str, chatHistory: str = '') -> str:\n",
    "    \n",
    "    try:\n",
    "        sqlQuery = sqlCoderAgent.generateAndRefineQuery(\n",
    "            userQuery=userQuery,\n",
    "            dialect='postgres',\n",
    "            tableInfo=tableInfo,\n",
    "            chatHistory=chatHistory\n",
    "        )\n",
    "        sqlQuery = cleanSqlQuery(sqlQuery)\n",
    "        return sqlQuery\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error generating SQL query: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def _executeSqlQuery(sqlQuery):\n",
    "    try:\n",
    "        data = sqlQueryTool.executeQuery(sqlQuery)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error executing SQL query: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlQuery = _generateQuery(qn1)\n",
    "logger.info(f\"Generated SQL Query: {sqlQuery}\")\n",
    "data = _executeSqlQuery(sqlQuery)\n",
    "logger.info(f\"SQL Query executed successfully. Data retrieved: {data}\")\n",
    "res1 = responseSummarizerAgent.generateSummaryWithReflection(response=data.to_string(), userQuery=qn1)\n",
    "res1 = cleanSummaryResponse(res1)\n",
    "logger.info(f\"Response generated: {res1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = cleanSummaryResponse(res1)\n",
    "logger.info(f\"Response generated: {res1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatHistory = '\\n'.join([qn1, res1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlQuery = _generateQuery(qn2, chatHistory)\n",
    "logger.info(f\"Generated SQL Query: {sqlQuery}\")\n",
    "data = _executeSqlQuery(sqlQuery)\n",
    "logger.info(f\"SQL Query executed successfully. Data retrieved: {data}\")\n",
    "res2 = responseSummarizerAgent.generateSummaryWithReflection(response=data.to_string(), userQuery=qn2)\n",
    "res2 = cleanSummaryResponse(res2)\n",
    "logger.info(f\"Response generated: {res2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing What?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiStuff.workflows import PolimapWorkflow\n",
    "\n",
    "workflow = PolimapWorkflow()\n",
    "# userQuery = \"Where do the renters live in Wills?\"\n",
    "userQuery = \"Is the Greens vote correlated to the number of renters?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedTables = workflow._selectTables(userQuery)\n",
    "selectedTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableInfo = workflow._getTableInfo(selectedTables)\n",
    "print(tableInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlQuery = workflow._generateQuery(userQuery=userQuery, tableInfo=tableInfo)\n",
    "print(sqlQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = workflow._executeSqlQuery(sqlQuery)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = workflow.responseSummarizerAgent.generateSummaryWithReflection(response=data.to_string(), userQuery=userQuery)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
