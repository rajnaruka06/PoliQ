{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 of AI_Stuff and ChatHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from AI_Stuff.Agent_Helpers import load_elecdata_postgres, clean_sql_query, SQLCoder, DDLCommandException, ChatHistory\n",
    "# from AI_Stuff.CustomAgents import SQLExpert, ResponseSummarizer\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# db = load_elecdata_postgres()\n",
    "# dialect = db.dialect\n",
    "# llm = ChatOpenAI(\n",
    "#     model=\"gpt-4o\",\n",
    "#     temperature=0,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     max_retries=2\n",
    "# )\n",
    "\n",
    "# schema_info = db.get_table_info()\n",
    "# sql_coder_agent = SQLExpert(llm = llm)\n",
    "# sql_query_tool = SQLCoder(db=db)\n",
    "# response_summarizer_agent = ResponseSummarizer(llm=llm)\n",
    "# history = ChatHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Works\n",
    "\n",
    "# from AI_Stuff.Workflows import elecdataworkflow\n",
    "# workflow = elecdataworkflow()\n",
    "# workflow.run(user_query=\"How many votes did each party get in the 2022 election?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Works\n",
    "\n",
    "# history = ChatHistory()\n",
    "# user_query = \"How many votes did each party get in the 2022 election?\"\n",
    "# sql_query = \"\"\n",
    "# response = \"\"\"### Summary of Votes by Party in the 2022 Election\n",
    "\n",
    "# #### Key Insights:\n",
    "# 1. **Top Parties by Votes:**\n",
    "#    - **Liberal Party** received the highest number of votes with **2,712,423** votes.\n",
    "#    - **Australian Labor Party** followed with **2,445,090** votes.\n",
    "#    - **Labor** (likely a duplicate or regional representation) garnered **1,290,950** votes.\n",
    "\n",
    "# 2. **Other Notable Parties:**\n",
    "#    - **Pauline Hanson's One Nation**: 562,511 votes.\n",
    "#    - **The Greens**: 963,961 votes.\n",
    "#    - **Independent** candidates collectively received 639,217 votes.\n",
    "#    - **Liberal National Party of Queensland**: 858,118 votes.\n",
    "\n",
    "# 3. **Smaller Parties and Independents:**\n",
    "#    - **United Australia Party**: 483,854 votes.\n",
    "#    - **The Nationals**: 457,945 votes.\n",
    "#    - **Queensland Greens**: 287,066 votes.\n",
    "#    - **Informal votes** (likely spoiled or invalid ballots): 674,035 votes.\n",
    "\n",
    "# 4. **Minor Parties and Low Vote Counts:**\n",
    "#    - Several minor parties received fewer than 50,000 votes each, such as **Australian Federation Party** (44,309 votes), **Shooters, Fishers and Farmers Party** (14,934 votes), and **Animal Justice Party** (61,698 votes).\n",
    "#    - Some parties received very minimal support, such as **Australian Democrats** (525 votes), **Reason Australia** (1,015 votes), and **Drew Pavlou Democratic Alliance** (848 votes).\n",
    "\n",
    "# #### Trends and Observations:\n",
    "# - **Dominance of Major Parties**: The Liberal and Labor parties dominate the vote count, collectively receiving over 6 million votes.\n",
    "# - **Significant Support for Minor Parties**: Parties like Pauline Hanson's One Nation and The Greens have substantial support, indicating a diverse political landscape.\n",
    "# - **High Number of Informal Votes**: The informal vote count is notably high at 674,035, which could indicate voter confusion or dissatisfaction.\n",
    "# - **Regional Variations**: The presence of parties like the Liberal National Party of Queensland and Queensland Greens suggests regional political dynamics.\n",
    "\n",
    "# #### Detailed Vote Counts:\n",
    "# - **Liberal Party**: 2,712,423 votes\n",
    "# - **Australian Labor Party**: 2,445,090 votes\n",
    "# - **Labor**: 1,290,950 votes\n",
    "# - **Pauline Hanson's One Nation**: 562,511 votes\n",
    "# - **The Greens**: 963,961 votes\n",
    "# - **Independent**: 639,217 votes\n",
    "# - **Liberal National Party of Queensland**: 858,118 votes\n",
    "# - **United Australia Party**: 483,854 votes\n",
    "# - **The Nationals**: 457,945 votes\n",
    "# - **Queensland Greens**: 287,066 votes\n",
    "# - **Informal**: 674,035 votes\n",
    "\n",
    "# #### Minor Parties (Selected):\n",
    "# - **Australian Federation Party**: 44,309 votes\n",
    "# - **Shooters, Fishers and Farmers Party**: 14,934 votes\n",
    "# - **Animal Justice Party**: 61,698 votes\n",
    "# - **Australian Democrats**: 525 votes\n",
    "# - **Reason Australia**: 1,015 votes\n",
    "# - **Drew Pavlou Democratic Alliance**: 848 votes\n",
    "\n",
    "# This summary provides a comprehensive overview of the vote distribution among various parties in the 2022 election, highlighting the dominance of major parties, the significant support for minor parties, and the notable number of informal votes.\"\"\"\n",
    "# chat = f\"\"\"User Query: {user_query}\\nSQL Query: {sql_query}\\nResponse: {response}\"\"\"\n",
    "# history.add(chat)\n",
    "# history.add(chat)\n",
    "# print([len(chat) for chat in history.get().split('\\n---\\n')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 of try1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:8000/run\"\n",
    "data = {\"user_query\": \"How many votes did each party get in the 2022 election?\"}\n",
    "headers = {\"accept\": \"application/json\", \"Content-Type\": \"application/json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url, json=data, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: ChatHistory V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Stuff.Agent_Helpers import ChatHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatHistory(user_id=\"test_user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding Functionality\n",
    "chat_id_1 = chat_history.addMessage(None, \"New Message Chat ID 1\")\n",
    "chat_id_2 = chat_history.addMessage(None, \"New Message Chat ID 2\")\n",
    "chat_history.addMessage(chat_id_1, \"chatid one append 1\")\n",
    "chat_history.addMessage(chat_id_2, \"chatid two append 1\")\n",
    "chat_history.addMessage(chat_id_1, \"chatid one append 2\")\n",
    "chat_history.addMessage(chat_id_2, \"chatid two append 2\")\n",
    "\n",
    "print(f\"chat id 1: {chat_id_1}, chat id 2: {chat_id_2}\")\n",
    "\n",
    "## Retrieving Functionality\n",
    "all_chats = chat_history.get_all_chats()\n",
    "print(\"All chats:\")\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Retrieving specific chat\n",
    "messages = chat_history.get_messages(chat_id_1)\n",
    "print(\"\\nMessages for chat_id_1:\")\n",
    "for message in messages:\n",
    "    print(message)\n",
    "\n",
    "## Retrieving most recent chats\n",
    "recent_chats = chat_history.get_recent_messages(chat_id=chat_id_1)\n",
    "print(\"\\nMost recent chats:\")\n",
    "for chat in recent_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Pinning Unpinning\n",
    "chat_history.pin_chat(chat_id_1)\n",
    "print(\"\\nChat_id_1 pinned.\")\n",
    "all_chats = chat_history.get_all_chats()\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "chat_history.unpin_chat(chat_id_1)\n",
    "print(\"Chat_id_1 unpinned.\")\n",
    "all_chats = chat_history.get_all_chats()\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Archiving\n",
    "chat_history.archive_chat(chat_id_2)\n",
    "print(\"\\nChat_id_2 archived.\")\n",
    "\n",
    "## Test Search\n",
    "search_results = chat_history.search_chats(\"services\")\n",
    "print(\"\\nSearch results for 'services':\")\n",
    "for result in search_results:\n",
    "    print(result)\n",
    "\n",
    "## Test Delete\n",
    "chat_history.delete_chat(chat_id_1)\n",
    "print(\"\\nChat_id_1 deleted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: try3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "base_url = \"http://127.0.0.1:8000\"\n",
    "\n",
    "def test_fetch_chat_history(user_id):\n",
    "    response = requests.get(f\"{base_url}/api/chats/all\", params={\"user_id\": user_id})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "def test_fetch_messages(chat_id, user_id):\n",
    "    response = requests.get(f\"{base_url}/api/chats/{chat_id}/messages\", params={\"user_id\": user_id})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "    \n",
    "def test_handle_send(message_content, chat_id=None, user_id='test_user'):\n",
    "    payload = {\n",
    "        \"content\": message_content,\n",
    "        \"chat_id\": chat_id\n",
    "    }\n",
    "    response = requests.post(f\"{base_url}/api/messages/send\", params={\"user_id\": user_id}, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "def test_handle_pin_chat(chat_id, user_id='test_user'):\n",
    "    response = requests.put(f\"{base_url}/api/chats/{chat_id}/pin\", params={\"user_id\": user_id})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "def test_handle_delete_chat(chat_id, user_id='test_user'):\n",
    "    response = requests.delete(f\"{base_url}/api/chats/{chat_id}/delete\", params={\"user_id\": user_id})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "def test_handle_archive_chat(chat_id, user_id='test_user'):\n",
    "    response = requests.put(f\"{base_url}/api/chats/{chat_id}/archive\", params={\"user_id\": user_id})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "def test_handle_search(term, user_id='test_user'):\n",
    "    response = requests.get(f\"{base_url}/api/chats/search\", params={\"term\": term, \"user_id\": user_id})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "user_id = 'test_user'\n",
    "chat_id = '66c6b793a74702e24ff8a187'\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client['ChatHistoryDB']\n",
    "collection = db[str(user_id)]\n",
    "\n",
    "print(test_fetch_chat_history('test_user'))\n",
    "print(\"*--\"*20)\n",
    "print(test_fetch_messages(chat_id, 'test_user'))\n",
    "print(\"*--\"*20)\n",
    "print(test_handle_send(\"How many votes did each party get in the 2022 election?\"))\n",
    "print(\"*--\"*20)\n",
    "print(test_fetch_messages(chat_id, 'test_user'))\n",
    "print(\"*--\"*20)\n",
    "print(test_handle_pin_chat(chat_id, 'test_user'))\n",
    "print(collection.find_one({\"chat_id\": '66c6b793a74702e24ff8a187'}))\n",
    "print(\"*--\"*20)\n",
    "print(test_handle_search('election'))\n",
    "print(\"*--\"*20)\n",
    "print(test_handle_archive_chat(chat_id))\n",
    "print(collection.find_one({\"chat_id\": chat_id}))\n",
    "print(\"*--\"*20)\n",
    "print(test_handle_delete_chat(chat_id))\n",
    "print(collection.find_one({\"chat_id\": chat_id}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Unfold. Check Any part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Stuff.Agent_Helpers import load_elecdata_postgres, clean_sql_query, SQLCoder, DDLCommandException\n",
    "from AI_Stuff.CustomAgents import SQLExpert, ResponseSummarizer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = load_elecdata_postgres()\n",
    "dialect = db.dialect\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")\n",
    "schema_info = db.get_table_info()\n",
    "sql_coder_agent = SQLExpert(llm = llm)\n",
    "sql_query_tool = SQLCoder(db=db)\n",
    "response_summarizer_agent = ResponseSummarizer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What are the most recent 3 records in elecdata_senatepreference table\"\n",
    "\n",
    "sql_query = sql_coder_agent.generate_query(\n",
    "            user_query = user_query\n",
    "            , dialect='postgres'\n",
    "            , table_info=schema_info\n",
    "            , chat_history=''\n",
    "        )\n",
    "sql_query = clean_sql_query(sql_query)\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = sql_query_tool.query_runner.invoke(sql_query)\n",
    "# print(res)\n",
    "\n",
    "# import re\n",
    "# from decimal import Decimal\n",
    "\n",
    "# def _parse_decimal(match):\n",
    "#     value = match.group(1)\n",
    "#     return Decimal(value)\n",
    "\n",
    "\n",
    "# import datetime\n",
    "\n",
    "# def _parse_datetime(match):\n",
    "#     date_args = list(map(int, match.group(1).split(',')))\n",
    "#     if match.group(2):  # Check if 'tzinfo' is present in the match\n",
    "#         dt = datetime.datetime(*date_args, tzinfo=datetime.timezone.utc)\n",
    "#     else:\n",
    "#         dt = datetime.datetime(*date_args)\n",
    "#     return f\"'{dt.isoformat()}'\"\n",
    "# import ast\n",
    "\n",
    "# def _custom_parser(res_str: str):\n",
    "#     # Replace Decimal instances\n",
    "#     res_str = re.sub(\n",
    "#         r\"Decimal\\('([^']+)'\\)\",\n",
    "#         lambda m: str(_parse_decimal(m)),\n",
    "#         res_str\n",
    "#     )\n",
    "#     # Replace datetime.datetime instances with or without timezone\n",
    "#     res_str = re.sub(\n",
    "#         r\"datetime\\.datetime\\(([\\d, ]+)(, tzinfo=datetime\\.timezone\\.utc)?\\)\",\n",
    "#         _parse_datetime,\n",
    "#         res_str\n",
    "#     )\n",
    "#     # Safely evaluate the string as a literal\n",
    "#     return ast.literal_eval(res_str)\n",
    "\n",
    "\n",
    "# res = _custom_parser(res)\n",
    "# res = pd.DataFrame.from_records(data=res, columns=range(len(res[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CREATE\" in sql_query or \"DELETE\" in sql_query or \"UPDATE\" in sql_query or \"ALTER\" in sql_query:\n",
    "    raise DDLCommandException\n",
    "else:\n",
    "    data = sql_query_tool.execute_query(sql_query)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response_summarizer_agent.summarize(user_query=user_query, dataframe=data)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Workflow Cabilities (22 Aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Stuff.Workflows import elecdataworkflow\n",
    "import time\n",
    "workflow = elecdataworkflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions = [\"Analyze the distribution of vacancies across states in the elecdata_pool table. What observations can you make?\"\n",
    "#     ,\"Compare the quota values for different states in the elecdata_pool table. What might explain the differences?\"\n",
    "#     ,\"Examine the elecdata_senatepreference table. What patterns do you notice in the transfer of votes between candidates?\"\n",
    "#     ,\"Using the elecdata_candidatepreference table, calculate the total votes received and the percentage of total votes for each candidate in the sample.\"\n",
    "#     ,\"Analyze the elecdata_votestack table to identify any correlations between primary votes and the state or location of voting.\"\n",
    "#     ,\"Using the elecdata_votetally table, compare the performance of candidates across different voting methods (ordinary, postal, pre-poll, etc.). What trends do you observe?\"\n",
    "#     ,\"Examine the elecdata_senateround table. How does the number of rounds vary between different pools, and what might this indicate about the competitiveness of the elections?\"\n",
    "#     ,\"Combine data from the elecdata_contention and elecdata_votetally tables to analyze how ballot position correlates with the number of primary votes received. What conclusions can you draw?\"\n",
    "#     ,\"Using data from multiple tables (elecdata_houseelection, elecdata_seat, elecdata_contention, elecdata_votetally), perform a comprehensive analysis of voting patterns and party performance across different elections and regions. Identify any notable trends or shifts in voter behavior.\"\n",
    "# ]\n",
    "\n",
    "questions = [\"Analyze the distribution of vacancies across states. What observations can you make?\"\n",
    "    ,\"Compare the quota values for different . What might explain the differences?\"\n",
    "    ,\"What patterns do you notice in the transfer of votes between candidates?\"\n",
    "    ,\"Calculate the total votes received and the percentage of total votes for each candidate.\"\n",
    "    ,\"Identify any correlations between primary votes and the state or location of voting.\"\n",
    "    ,\"Compare the performance of candidates across different voting methods (ordinary, postal, pre-poll, etc.). What trends do you observe?\"\n",
    "    ,\"How does the number of rounds vary between different pools, and what might this indicate about the competitiveness of the elections?\"\n",
    "    ,\"Analyze how ballot position correlates with the number of primary votes received. What conclusions can you draw?\"\n",
    "    ,\"Perform a comprehensive analysis of voting patterns and party performance across different elections and regions. Identify any notable trends or shifts in voter behavior.\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    res = workflow.run(user_query=question)\n",
    "    print(f\"Question: {question}\\nResponse: {res}\\n\")\n",
    "    print('---'*20)\n",
    "    time.sleep(180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Agent_Helpers.py 23-Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from AI_Stuff.Agent_Helpers import load_polimap_postgres, load_elecdata_postgres, load_llm, web_search, SQLCoder, ChatHistory\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "import tiktoken\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PyPDF2 import PdfReader\n",
    "from pymongo import MongoClient, TEXT\n",
    "from bson import ObjectId\n",
    "import gridfs\n",
    "import io\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "from decimal import Decimal\n",
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test PostgreSQL database connection\n",
    "try:\n",
    "    db1 = load_polimap_postgres()\n",
    "    db2 = load_elecdata_postgres()\n",
    "    if isinstance(db1, SQLDatabase) and isinstance(db2, SQLDatabase):\n",
    "        print(\"Postgres connections successful.\")\n",
    "    else:\n",
    "        print(\"Error connecting to Postgres.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Postgres: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test LLM loading\n",
    "try:\n",
    "    openai_llm = load_llm(llm_name='gpt', model='gpt-4o')\n",
    "    anthropic_llm = load_llm(llm_name='claude', model='claude-3-opus-20240229')\n",
    "    if isinstance(openai_llm, ChatOpenAI) and isinstance(anthropic_llm, ChatAnthropic):\n",
    "        print(\"LLMs loaded successfully.\")\n",
    "    else:\n",
    "        print(\"Error loading LLMs.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading LLMs: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search(\"How many votes did each party get in the 2022 election?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SQLCoder\n",
    "try:\n",
    "    sql_coder = SQLCoder(db2)\n",
    "    query = \"\"\"SELECT primary_votes FROM elecdata_votestack where primary_votes = 434;\"\"\"\n",
    "    df = sql_coder.execute_query(query)\n",
    "    print(\"SQL Query Result:\", df)\n",
    "except Exception as e:\n",
    "    print(f\"Error executing SQL query: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ChatHistory 23-Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Stuff.Agent_Helpers import ChatHistory\n",
    "\n",
    "# Create an instance of the ChatHistory class\n",
    "chat_history = ChatHistory(user_id=\"test_user\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = chat_history.get_all_chats()\n",
    "chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add messages to a chat session\n",
    "chat_id = chat_history.add_message(chat_id='66c8c2e45dd82d23781eab0d', content=\"Yes, Shooot it!\", is_user=False)\n",
    "chat_history.add_message(chat_id=chat_id, content=\"Just testing\", is_user=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve messages for a chat session\n",
    "messages = chat_history.get_messages(chat_id)\n",
    "print(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.get_recent_messages(chat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "csv_file = b\"col1,col2\\nval1,val2\"\n",
    "file_id = chat_history.upload_doc(chat_id, csv_file, \"test.csv\", \"csv\")\n",
    "\n",
    "file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from fpdf import FPDF\n",
    "import tempfile\n",
    "\n",
    "# Create a simple PDF file\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "pdf.cell(200, 10, txt=\"Hello World!\", ln=True, align=\"C\")\n",
    "\n",
    "# Create a temporary file to save the PDF\n",
    "with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_file:\n",
    "    pdf.output(temp_file.name)\n",
    "    temp_file.seek(0)  # Move to the start of the file\n",
    "\n",
    "    # Read the file into a BytesIO object\n",
    "    pdf_file = temp_file.read()\n",
    "\n",
    "# Use the BytesIO object to upload the PDF document\n",
    "file_id = chat_history.upload_doc(chat_id, pdf_file, \"valid_test.pdf\", \"pdf\")\n",
    "print(f\"Uploaded Valid PDF Doc ID: {file_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get documents context\n",
    "doc_context = chat_history.get_documents_context(chat_id)\n",
    "print(f\"Document Context: {doc_context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search chats\n",
    "search_results = chat_history.search_chats(\"Hello\")\n",
    "print(f\"Search Results: {search_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Edge Cases# Invalid document type\n",
    "try:\n",
    "    chat_history.upload_doc(chat_id, csv_file, \"test.txt\", \"txt\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty messages\n",
    "chat_id_empty = chat_history.add_message(chat_id=None, content=\"\", is_user=True)\n",
    "messages_empty = chat_history.get_messages(chat_id_empty)\n",
    "print(f\"Empty Messages: {messages_empty}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-existent chat ID\n",
    "messages_non_existent = chat_history.get_messages(\"non_existent_id\")\n",
    "print(f\"Messages for non-existent chat ID: {messages_non_existent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Cleanup\n",
    "\n",
    "# Delete chat\n",
    "chat_history.delete_chat(chat_id)\n",
    "print(f\"Deleted Chat ID: {chat_id}\")\n",
    "\n",
    "# Archive and Unpin Chats\n",
    "chat_history.archive_chat(chat_id)\n",
    "chat_history.pin_chat(chat_id)\n",
    "chat_history.unpin_chat(chat_id)\n",
    "print(\"Archived and unpinned chat.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Chain Of Thoughts in SQLQuery Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "## Chain Of Thoughts and CRAG\n",
    "class SQLExpert:\n",
    "    def __init__(self, llm):\n",
    "        llm = llm\n",
    "\n",
    "    def generate_query(self, user_query: str, dialect: str, table_info: str, chat_history: str = '') -> str:\n",
    "        relevant_tables = identify_relevant_tables(user_query, table_info, chat_history)\n",
    "        query_steps = identify_query_steps(user_query, relevant_tables, chat_history)\n",
    "        sql_query = generate_sql(user_query, dialect, relevant_tables, query_steps, chat_history)\n",
    "        if sql_query.lower().strip() != \"invalid user query - not related to the database\":\n",
    "            sql_query = correct_query(sql_query, dialect, table_info, user_query, chat_history)\n",
    "        return sql_query\n",
    "\n",
    "    def identify_relevant_tables(self, user_query: str, table_info: str, chat_history: str) -> List[str]:\n",
    "        template = \"\"\"Given the user query and available tables, identify the list of tables that are relevant to answer the query.\n",
    "        Only include tables that are directly related to the query. Do not include any tables that are not mentioned in the table information.\n",
    "\n",
    "        User Query: {user_query}\n",
    "        Table Information: {table_info}\n",
    "        Chat History: {chat_history}\n",
    "\n",
    "        Relevant Tables (comma-separated list):\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        chain = prompt | llm\n",
    "        result = chain.invoke({\n",
    "            \"user_query\": user_query,\n",
    "            \"table_info\": table_info,\n",
    "            \"chat_history\": chat_history\n",
    "        }).content.strip()\n",
    "        return [table.strip() for table in result.split(',')]\n",
    "\n",
    "    def identify_query_steps(self, user_query: str, relevant_tables: List[str], chat_history: str) -> List[str]:\n",
    "        template = \"\"\"Given the user query and relevant tables, identify the steps that should be taken to answer the query.\n",
    "        Provide a numbered list of high-level steps, focusing on the logical flow of data manipulation and analysis.\n",
    "\n",
    "        User Query: {user_query}\n",
    "        Relevant Tables: {relevant_tables}\n",
    "        Chat History: {chat_history}\n",
    "\n",
    "        Query Steps:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        chain = prompt | llm\n",
    "        result = chain.invoke({\n",
    "            \"user_query\": user_query,\n",
    "            \"relevant_tables\": \", \".join(relevant_tables),\n",
    "            \"chat_history\": chat_history\n",
    "        }).content.strip()\n",
    "        return [step.strip() for step in result.split('\\n') if step.strip()]\n",
    "\n",
    "    def generate_sql(self, user_query: str, dialect: str, relevant_tables: List[str], query_steps: List[str], chat_history: str) -> str:\n",
    "        template = \"\"\"Given the user query, relevant tables, and query steps, generate ONLY a syntactically correct {dialect} SQL query.\n",
    "        Follow these rules:\n",
    "        - Do not assume any table or columns that are not mentioned in the relevant tables.\n",
    "        - Do not include any CREATE, DELETE, UPDATE, or ALTER statements.\n",
    "        - Use Common Table Expressions (CTEs) for data manipulation instead of subqueries.\n",
    "        - Never use * in the SELECT statement. Always specify the columns you want to retrieve, even in CTEs.\n",
    "        - Use GROUP BY instead of DISTINCT where applicable.\n",
    "        - Do not include any LIMIT or OFFSET clauses unless the user query explicitly requires it.\n",
    "        - Use the information from the chat history if it adds context or relevant details to the current question.\n",
    "        - If the query cannot be generated, just return one sentence: \"Invalid User Query - Not related to the Database.\".\n",
    "        - Do not include any explanations, comments, or additional text. Return ONLY the SQL query.\n",
    "\n",
    "        User Query: {user_query}\n",
    "        Dialect: {dialect}\n",
    "        Relevant Tables: {relevant_tables}\n",
    "        Query Steps: {query_steps}\n",
    "        Chat History: {chat_history}\n",
    "\n",
    "        SQL Query:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        chain = prompt | llm\n",
    "        sql_query = chain.invoke({\n",
    "            \"user_query\": user_query,\n",
    "            \"dialect\": dialect,\n",
    "            \"relevant_tables\": \", \".join(relevant_tables),\n",
    "            \"query_steps\": \"\\n\".join(query_steps),\n",
    "            \"chat_history\": chat_history\n",
    "        }).content.strip()\n",
    "\n",
    "        return sql_query\n",
    "\n",
    "\n",
    "## Update\n",
    "\n",
    "    def correct_query(self, sql_query: str, dialect: str, table_info: str, user_query: str, chat_history: str) -> str:\n",
    "        corrective_template = \"\"\"You are a SQL expert. Given a generated SQL query, evaluate it to ensure it adheres to the following criteria:\n",
    "        - Does not Assume any table or columns that are not mentioned.\n",
    "        - Does not include any CREATE, DELETE, UPDATE, or ALTER statements in your responses.\n",
    "        - Using Common Table Expressions (CTEs) for data manipulation instead of subqueries.\n",
    "        - No use of * in the SELECT statement. The columns wanted are always specified to retrieve. Even while querying from Common Table Expressions.\n",
    "        - Group by is used instead of distinct where applicable.\n",
    "        - This is a syntactically correct {dialect} query to run using Only the tables and columns that are mentined in the database.\n",
    "\n",
    "        Do not include an improved SQL Query and do not write or suggest any code. Just provide feedback on the existing query and suggest improvements.\n",
    "        If the query is already good, your response should just be one word: \"All good\". Otherwise, provide feedback and suggest improvements. \n",
    "        If the query can not be generated, your response should just be one sentence: \"Invalid User Query - Not related to the Database\".\n",
    "        Do not include an improved query.\n",
    "\n",
    "        Table Info: {table_info}\n",
    "        Chat History: {chat_history}\n",
    "        User Query: {user_query}\n",
    "        Generated SQL Query: {sql_query}\n",
    "        Correction:\n",
    "        \"\"\"\n",
    "        corrective_prompt = PromptTemplate.from_template(corrective_template)\n",
    "        corrective_chain = corrective_prompt | self.llm\n",
    "        correction_result = corrective_chain.invoke({\n",
    "            \"user_query\": user_query,\n",
    "            \"sql_query\": sql_query,\n",
    "            \"dialect\": dialect,\n",
    "            \"table_info\": table_info,\n",
    "            \"chat_history\": chat_history\n",
    "        }).content.strip()\n",
    "\n",
    "        if correction_result.lower().strip() != \"all good\":\n",
    "            sql_query = self.adjust_query(sql_query, dialect, table_info, user_query, correction_result, chat_history)\n",
    "\n",
    "        return sql_query\n",
    "\n",
    "    def adjust_query(self, sql_query: str, dialect: str, table_info: str, user_query: str, correction: str, chat_history: str) -> str:\n",
    "        adjustment_template = \"\"\"You are a SQL expert. Given a generated SQL query, correction feedback, dialect, table information, and user query, adjust the query to make it more accurate and better answer the user query.\n",
    "        If the query can not be generated, your response should just be one sentence: \"Invalid User Query - Not related to the Database\".\n",
    "        If no changes are required, return the original query as is.\n",
    "        If changes are required, follow these rules:\n",
    "        - Do not Assume any table or columns that are not mentioned.\n",
    "        - Do not include any CREATE, DELETE, UPDATE, or ALTER statements in your responses.\n",
    "        - Use Common Table Expressions (CTEs) for data manipulation instead of subqueries.\n",
    "        - Never use * in the SELECT statement. Always specify the columns you want to retrieve. Even if you are querying from Common Table Expressions.\n",
    "        - Use group by instead of distinct where applicable.\n",
    "        - Do not include any LIMIT, or OFFSET clauses in your responses unless the user query requires it.\n",
    "        - Use the information from the chat history if they add context or relevant details to the current question. Focus primarily on the most recent and relevant questions. If the previous questions do not add any context, just focus on the current question.\n",
    "\n",
    "        Dialect: {dialect}\n",
    "        Table Info: {table_info}\n",
    "        User Query: {user_query}\n",
    "        Chat History: {chat_history}\n",
    "        Generated SQL Query: {sql_query}\n",
    "        Correction Feedback: {correction}\n",
    "        Adjusted SQL Query:\n",
    "        \"\"\"\n",
    "        adjustment_prompt = PromptTemplate.from_template(adjustment_template)\n",
    "        adjustment_chain = adjustment_prompt | self.llm\n",
    "        adjusted_query = adjustment_chain.invoke({\n",
    "            \"user_query\": user_query,\n",
    "            \"sql_query\": sql_query,\n",
    "            \"dialect\": dialect,\n",
    "            \"table_info\": table_info,\n",
    "            \"correction\": correction,\n",
    "            \"chat_history\": chat_history\n",
    "        }).content.strip()\n",
    "\n",
    "        return adjusted_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Stuff.Agent_Helpers import load_elecdata_postgres, clean_sql_query, SQLCoder, DDLCommandException\n",
    "from AI_Stuff.CustomAgents import ResponseSummarizer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "db = load_elecdata_postgres()\n",
    "dialect = db.dialect\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")\n",
    "schema_info = db.get_table_info()\n",
    "sql_coder_agent = SQLExpert(llm = llm)\n",
    "sql_query_tool = SQLCoder(db=db)\n",
    "response_summarizer_agent = ResponseSummarizer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Workflow(user_query: str):\n",
    "    sql_query = sql_coder_agent.generate_query(\n",
    "        user_query = user_query\n",
    "        , dialect='postgres'\n",
    "        , table_info=schema_info\n",
    "        , chat_history=''\n",
    "    )\n",
    "    sql_query = clean_sql_query(sql_query)\n",
    "    if \"CREATE\" in sql_query or \"DELETE\" in sql_query or \"UPDATE\" in sql_query or \"ALTER\" in sql_query:\n",
    "        raise DDLCommandException\n",
    "    elif sql_query.lower().strip() == \"invalid user query - not related to the database.\":\n",
    "        return sql_query\n",
    "    else:\n",
    "        data = sql_query_tool.execute_query(sql_query)\n",
    "        response = response_summarizer_agent.summarize(user_query=user_query, dataframe=data)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"Analyze the distribution of vacancies across states. What observations can you make?\"\n",
    "    ,\"What patterns do you notice in the transfer of votes between candidates?\"\n",
    "    ,\"Calculate the total votes received and the percentage of total votes for each candidate.\"\n",
    "    ,\"Identify any correlations between primary votes and the state or location of voting.\"\n",
    "    ,\"Compare the performance of candidates across different voting methods (ordinary, postal, pre-poll, etc.). What trends do you observe?\"\n",
    "    ,\"How does the number of rounds vary between different pools, and what might this indicate about the competitiveness of the elections?\"\n",
    "    ,\"Analyze how ballot position correlates with the number of primary votes received. What conclusions can you draw?\"\n",
    "    ,\"Perform a comprehensive analysis of voting patterns and party performance across different elections and regions. Identify any notable trends or shifts in voter behavior.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for question in questions[1:3]:\n",
    "    res = Workflow(user_query=question)\n",
    "    print(f\"Question: {question}\\nResponse: {res}\\n\")\n",
    "    print('---'*20)\n",
    "    time.sleep(180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiDB SQL Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Failed Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent_Helpers 24-Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for loadPostgresDatabase function\n",
    "\n",
    "from AI_Stuff.Agent_Helpers2 import *\n",
    "import os\n",
    "\n",
    "db_name = os.environ.get(\"POLIMAP_DB_NAME\")\n",
    "try:\n",
    "    # Test loading a database with valid input\n",
    "    db = loadPostgresDatabase(db_name)\n",
    "    print(\"Database loaded successfully:\", db)\n",
    "except ValueError as e:\n",
    "    print(\"ValueError:\", e)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "\n",
    "\n",
    "db_name = os.environ.get(\"ELECDATA_DB_NAME\")\n",
    "try:\n",
    "    # Test loading a database with valid input\n",
    "    db = loadPostgresDatabase(db_name)\n",
    "    print(\"Database loaded successfully:\", db)\n",
    "except ValueError as e:\n",
    "    print(\"ValueError:\", e)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Test for `loadLLM`\n",
    "try:\n",
    "    llm_gpt = loadLLM(llmName='gpt')\n",
    "    llm_claude = loadLLM(llmName='claude')\n",
    "    print(\"loadLLM: Success\")\n",
    "except ValueError as e:\n",
    "    print(f\"loadLLM: Failed with ValueError - {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"loadLLM: Failed with Exception - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Test for `webSearch`\n",
    "try:\n",
    "    result = webSearch(\"OpenAI GPT-4\")\n",
    "    print(f\"webSearch: Success - {result[:100]}...\")  # Print only the first 100 characters\n",
    "except Exception as e:\n",
    "    print(f\"webSearch: Failed with Exception - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Test for `cleanSqlQuery`\n",
    "test_query_1 = \"### Adjusted SQL Query: SELECT * FROM users\"\n",
    "test_query_2 = \"sql SELECT * FROM orders SQLQuery: SELECT id, order_date FROM orders\"\n",
    "test_query_3 = \"SELECT id FROM customers WHERE name = 'John Doe'\"\n",
    "\n",
    "cleaned_query_1 = cleanSqlQuery(test_query_1)\n",
    "cleaned_query_2 = cleanSqlQuery(test_query_2)\n",
    "cleaned_query_3 = cleanSqlQuery(test_query_3)\n",
    "\n",
    "print(f\"cleanSqlQuery Test 1: {cleaned_query_1}\")\n",
    "print(f\"cleanSqlQuery Test 2: {cleaned_query_2}\")\n",
    "print(f\"cleanSqlQuery Test 3: {cleaned_query_3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from fpdf import FPDF\n",
    "import tempfile\n",
    "from aiStuff.agentHelpers import ChatHistory\n",
    "chat_history = ChatHistory(userId=\"test_user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding Functionality\n",
    "chat_id_1 = chat_history.addMessage(None, \"New Message Chat ID 1\")\n",
    "chat_id_2 = chat_history.addMessage(None, \"New Message Chat ID 2\")\n",
    "chat_history.addMessage(chat_id_1, \"chatid one append 1\")\n",
    "chat_history.addMessage(chat_id_2, \"chatid two append 1\")\n",
    "chat_history.addMessage(chat_id_1, \"chatid one append 2\")\n",
    "chat_history.addMessage(chat_id_2, \"chatid two append 2\")\n",
    "\n",
    "print(f\"chat id 1: {chat_id_1}, chat id 2: {chat_id_2}\")\n",
    "\n",
    "## Retrieving Functionality\n",
    "all_chats = chat_history.getAllChats()\n",
    "print(\"All chats:\")\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Retrieving specific chat\n",
    "messages = chat_history.getMessages(chat_id_1)\n",
    "print(\"\\nMessages for chat_id_1:\")\n",
    "for message in messages:\n",
    "    print(message)\n",
    "    msg_id = message['messageId']\n",
    "\n",
    "## Retrieving specific message\n",
    "msg = chat_history.getMessage(chat_id_1, msg_id)\n",
    "print(f\"\\nRetrieved message: {msg}\")\n",
    "\n",
    "## Retrieving most recent chats\n",
    "recent_chats = chat_history.getRecentMessages(chat_id_1)\n",
    "print(\"\\nMost recent chats:\")\n",
    "for chat in recent_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Pinning Unpinning\n",
    "chat_history.pinChat(chat_id_1)\n",
    "print(\"\\nChat_id_1 pinned.\")\n",
    "all_chats = chat_history.getAllChats()\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "chat_history.unpinChat(chat_id_1)\n",
    "print(\"\\nChat_id_1 unpinned.\")\n",
    "all_chats = chat_history.getAllChats()\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Archiving and Unarchiving\n",
    "chat_history.archiveChat(chat_id_2)\n",
    "print(\"\\nChat_id_2 archived.\")\n",
    "all_chats = chat_history.getAllChats()\n",
    "print(\"All chats:\")\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "\n",
    "chat_history.unarchiveChat(chat_id_2)\n",
    "print(\"\\nChat_id_2 unarchived.\")\n",
    "all_chats = chat_history.getAllChats()\n",
    "print(\"All chats:\")\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Title Update\n",
    "chat_history.updateChatTitle(chat_id_1, \"Updated Chat Title\")\n",
    "print(\"\\nChat_id_1 title updated.\")\n",
    "all_chats = chat_history.getAllChats()\n",
    "print(\"All chats:\")\n",
    "for chat in all_chats:\n",
    "    print(chat)\n",
    "\n",
    "## Test Search\n",
    "search_results = chat_history.searchChats(\"append\")\n",
    "print(\"\\nSearch results for 'append':\")\n",
    "for result in search_results:\n",
    "    print(result)\n",
    "\n",
    "## CSV Upload\n",
    "csv_file = b\"col1,col2\\nval1,val2\"\n",
    "file_id = chat_history.uploadDoc(chat_id_1, csv_file, \"test.csv\", \"csv\")\n",
    "print(f\"\\nUploaded CSV document ID: {file_id}\")\n",
    "\n",
    "## PDF Upload\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "pdf.cell(200, 10, txt=\"Hello World!\", ln=True, align=\"C\")\n",
    "with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_file:\n",
    "    pdf.output(temp_file.name)\n",
    "    temp_file.seek(0)\n",
    "    pdf_file = temp_file.read()\n",
    "file_id = chat_history.uploadDoc(chat_id_1, pdf_file, \"valid_test.pdf\", \"pdf\")\n",
    "print(f\"U\\nploaded Valid PDF Doc ID: {file_id}\")\n",
    "\n",
    "## text upload\n",
    "text_file = b\"Hello World!\"\n",
    "file_id = chat_history.uploadDoc(chat_id_1, text_file, \"test.txt\", \"txt\")\n",
    "print(f\"\\nUploaded Text Doc ID: {file_id}\")\n",
    "\n",
    "## Get documents context\n",
    "doc_context = chat_history.getDocumentsContext(chat_id_1)\n",
    "print(f\"\\nDocument Context: {doc_context}\")\n",
    "\n",
    "## Edge Case Invalid document type\n",
    "try:\n",
    "    chat_history.uploadDoc(chat_id_1, csv_file, \"test.txt\", \"txt\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "## Test Edit Message Functionality\n",
    "chat_history.addMessage(chat_id_1, \"chatid one append 3\")\n",
    "chat_history.addMessage(chat_id_1, \"chatid one append 4\")\n",
    "messages = chat_history.getMessages(chat_id_1)\n",
    "print(\"\\nMessages for chat_id_1:\")\n",
    "for message in messages:\n",
    "    print(message)\n",
    "third_message_id = messages[2]['messageId']\n",
    "chat_history.updateMessage(chat_id_1, third_message_id, \"Updated content for third message\")\n",
    "messages = chat_history.getMessages(chat_id_1)\n",
    "print(\"\\nUpdated messages for chat_id_1:\")\n",
    "for message in messages:\n",
    "    print(message)\n",
    "\n",
    "\n",
    "## Test Delete\n",
    "chat_history.deleteChat(chat_id_2)\n",
    "print(\"\\nChat_id_2 deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing New Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aiStuff.workflows import ElecDataWorkflow\n",
    "# workflow = ElecDataWorkflow()\n",
    "\n",
    "# res = workflow.processUserQuery(userQuery=\"HI\")\n",
    "# print(res)\n",
    "\n",
    "# res = workflow.processUserQuery(userQuery=\"I feel like I have the prettiest girlfriend in the world!\")\n",
    "# print(res)\n",
    "\n",
    "# res = workflow.processUserQuery(userQuery=\"How many votes did each party get in 2022?\")\n",
    "# print(res)\n",
    "\n",
    "# res = workflow.processUserQuery(userQuery=\"How can the pretty use this?\")\n",
    "# print(res)\n",
    "\n",
    "# res = workflow.processUserQuery(userQuery=\"I just want to knw about top 10 parties.\")\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Metadata and tablenames --> Get relevent tables --> Get TableInfo --> Continue: Does Not work due to lack of FK information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# from typing import List, Dict, Any\n",
    "# from langchain_core.prompts import PromptTemplate\n",
    "# from langchain.base_language import BaseLanguageModel\n",
    "# from aiStuff.agentHelpers import loadPostgresDatabase, cleanSqlQuery, QuerySQLTool, InvalidUserQueryException, NoDataFoundException\n",
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# # logger = logging.getLogger(__name__)\n",
    "\n",
    "# class ElecDataWorkflow2:\n",
    "#     def __init__(self, llm: BaseLanguageModel, dbName: str = 'JL'):\n",
    "#         self.llm = llm\n",
    "#         self.dbName = dbName\n",
    "#         self.sqlQueryTool = QuerySQLTool(dbName=self.dbName)\n",
    "#         self._setTableInfo()\n",
    "#         self._setDialect()\n",
    "#         self.MAX_RETRIES = 3\n",
    "\n",
    "#     def _setTableInfo(self):\n",
    "#         with loadPostgresDatabase(self.dbName) as db:\n",
    "#             self.tableInfo = db.get_table_info()\n",
    "\n",
    "#     def _setDialect(self):\n",
    "#         with loadPostgresDatabase(self.dbName) as db:\n",
    "#             self.dialect = db.dialect\n",
    "\n",
    "#     def _selectPotentialTables(self, userQuery: str) -> List[str]:\n",
    "#         template = \"\"\"\n",
    "#         Given the following user query and available tables, select the most relevant tables that might be needed to answer the query.\n",
    "        \n",
    "#         User Query: {userQuery}\n",
    "        \n",
    "#         Available Tables:\n",
    "#         {tableInfo}\n",
    "        \n",
    "#         Return a comma-separated list of table names, without any additional explanation.\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate.from_template(template)\n",
    "#         chain = prompt | self.llm\n",
    "#         result = chain.invoke({\"userQuery\": userQuery, \"tableInfo\": self.tableInfo})\n",
    "#         return [table.strip() for table in result.content.split(',')]\n",
    "\n",
    "#     def _determineJoinConditions(self, tables: List[str]) -> Dict[str, str]:\n",
    "#         template = \"\"\"\n",
    "#         Given the following target tables, determine the appropriate join conditions between them. (JOIN ONLY AMONGST TARGET TABLES)\n",
    "        \n",
    "#         Target Tables: {tables}\n",
    "        \n",
    "#         Table Information:\n",
    "#         {tableInfo}\n",
    "        \n",
    "#         Return a JSON object where the keys are pairs of table names (e.g., \"table1__table2\") and the values are the join conditions.\n",
    "#         Just return a json object that can be loaded into json directly and nothing else.\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate.from_template(template)\n",
    "#         chain = prompt | self.llm\n",
    "#         result = chain.invoke({\"tables\": ', '.join(tables), \"tableInfo\": self.tableInfo}).content\n",
    "#         result = result.replace('`', '').replace('json', '')\n",
    "#         return json.loads(result)\n",
    "\n",
    "#     def _selectFilteringColumns(self, tables: List[str], userQuery: str) -> List[str]:\n",
    "#         template = \"\"\"\n",
    "#         Given the following user query and selected tables, determine which columns should be used for filtering the results.\n",
    "        \n",
    "#         User Query: {userQuery}\n",
    "#         Selected Tables: {tables}\n",
    "        \n",
    "#         Table Information:\n",
    "#         {tableInfo}\n",
    "        \n",
    "#         Return a comma-separated list of column names (including table names, e.g., \"table.column\"), without any additional explanation.\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate.from_template(template)\n",
    "#         chain = prompt | self.llm\n",
    "#         result = chain.invoke({\"userQuery\": userQuery, \"tables\": ', '.join(tables), \"tableInfo\": self.tableInfo})\n",
    "#         return [col.strip() for col in result.content.split(',')]\n",
    "\n",
    "#     def _executeQueryWithRetry(self, queryFunc, *args, **kwargs):\n",
    "#         for attempt in range(self.MAX_RETRIES):\n",
    "#             try:\n",
    "#                 query = queryFunc(*args, **kwargs)\n",
    "#                 result = self.sqlQueryTool.executeQuery(query)\n",
    "#                 return result\n",
    "#             except Exception as e:\n",
    "#                 # logger.warning(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "#                 print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "#                 if attempt == self.MAX_RETRIES - 1:\n",
    "#                     raise\n",
    "#                 # Provide feedback to the AI for query refinement\n",
    "#                 kwargs['error_feedback'] = str(e)\n",
    "        \n",
    "#         raise Exception(f\"Failed to execute query after {self.MAX_RETRIES} attempts\")\n",
    "\n",
    "#     def _generateDistinctQuery(self, tables: List[str], joinConditions: Dict[str, str], filteringColumns: List[str], error_feedback: str = \"\") -> str:\n",
    "#         template = \"\"\"\n",
    "#         Generate a SQL query to select distinct values from the specified columns and tables.\n",
    "#         Use the provided join conditions to connect the tables.\n",
    "        \n",
    "#         Tables: {tables}\n",
    "#         Join Conditions: {joinConditions}\n",
    "#         Filtering Columns: {filteringColumns}\n",
    "        \n",
    "#         Table Information:\n",
    "#         {tableInfo}\n",
    "        \n",
    "#         Error Feedback: {error_feedback}\n",
    "        \n",
    "#         Rules:\n",
    "#         1. Use SELECT DISTINCT for the specified filtering columns only.\n",
    "#         2. Include only the tables necessary for the filtering columns in the FROM and JOIN clauses.\n",
    "#         3. Use the provided join conditions to connect tables, but only include joins necessary for the filtering columns.\n",
    "#         4. Do not include any WHERE clauses or additional filtering.\n",
    "#         5. Use table aliases if necessary for clarity.\n",
    "#         6. Ensure the query is compatible with PostgreSQL.\n",
    "#         7. If error feedback is provided, adjust the query to address the issue.\n",
    "#         8. Do not include any aggregations or GROUP BY clauses.\n",
    "#         9. The goal is to get unique combinations of values in the filtering columns, not to perform any calculations.\n",
    "\n",
    "#         Return only the SQL query without any additional explanation.\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate.from_template(template)\n",
    "#         chain = prompt | self.llm\n",
    "#         result = chain.invoke({\n",
    "#             \"tables\": ', '.join(tables),\n",
    "#             \"joinConditions\": json.dumps(joinConditions),\n",
    "#             \"filteringColumns\": ', '.join(filteringColumns),\n",
    "#             \"tableInfo\": self.tableInfo,\n",
    "#             \"error_feedback\": error_feedback\n",
    "#         })\n",
    "#         return cleanSqlQuery(result.content)\n",
    "\n",
    "#     def _determineFilterValues(self, distinctQueryResult: pd.DataFrame, userQuery: str) -> Dict[str, Any]:\n",
    "#         template = \"\"\"\n",
    "#         Given the following user query and distinct values for potential filtering columns, determine the appropriate filter values to use in the SQL query.\n",
    "        \n",
    "#         User Query: {userQuery}\n",
    "        \n",
    "#         Distinct Values:\n",
    "#         {distinctValues}\n",
    "        \n",
    "#         Return a JSON object where the keys are column names and the values are the filter values to use. If a column should not be used for filtering, omit it from the result.\n",
    "#         Just return a json object that can be loaded into json directly and nothing else.\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate.from_template(template)\n",
    "#         chain = prompt | self.llm\n",
    "#         result = chain.invoke({\"userQuery\": userQuery, \"distinctValues\": distinctQueryResult.to_json(orient='records')}).content\n",
    "#         result = result.replace('`', '').replace('json', '')\n",
    "#         return json.loads(result)\n",
    "\n",
    "#     def _generateFinalQuery(self, tables: List[str], joinConditions: Dict[str, str], filteringColumns: List[str], filterValues: Dict[str, Any], userQuery: str, error_feedback: str = \"\") -> str:\n",
    "#         template = \"\"\"\n",
    "#         Generate a SQL query based on the following information:\n",
    "        \n",
    "#         User Query: {userQuery}\n",
    "#         Tables: {tables}\n",
    "#         Join Conditions: {joinConditions}\n",
    "#         Filtering Columns: {filteringColumns}\n",
    "#         Filter Values: {filterValues}\n",
    "        \n",
    "#         Table Information:\n",
    "#         {tableInfo}\n",
    "        \n",
    "#         Error Feedback: {error_feedback}\n",
    "        \n",
    "#         Rules:\n",
    "#         1. Generate a complete SQL query that answers the user's question.\n",
    "#         2. Include appropriate SELECT, FROM, JOIN, and WHERE clauses.\n",
    "#         3. Use the provided join conditions to connect tables.\n",
    "#         4. Use the filtering columns and filter values to create appropriate WHERE conditions.\n",
    "#         5. Do not use subqueries; use CTEs if necessary.\n",
    "#         6. Ensure the query is compatible with PostgreSQL.\n",
    "#         7. Use table aliases if necessary for clarity.\n",
    "#         8. If error feedback is provided, adjust the query to address the issue.\n",
    "#         9. ONLY use column names that are explicitly mentioned in the Table Information.\n",
    "#         10. Do not hallucinate or invent column names.\n",
    "\n",
    "#         Return only the SQL query without any additional explanation.\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate.from_template(template)\n",
    "#         chain = prompt | self.llm\n",
    "#         result = chain.invoke({\n",
    "#             \"userQuery\": userQuery,\n",
    "#             \"tables\": ', '.join(tables),\n",
    "#             \"joinConditions\": json.dumps(joinConditions),\n",
    "#             \"filteringColumns\": ', '.join(filteringColumns),\n",
    "#             \"filterValues\": json.dumps(filterValues),\n",
    "#             \"tableInfo\": self.tableInfo,\n",
    "#             \"error_feedback\": error_feedback\n",
    "#         })\n",
    "#         query = cleanSqlQuery(result.content)\n",
    "        \n",
    "#         # Implement CRAG (Constrained Retrieval Augmented Generation)\n",
    "#         crag_template = \"\"\"\n",
    "#         You are a SQL expert. Review the following SQL query and ensure it follows all the rules and is runnable. \n",
    "#         Do not hallucinate on table names, column names, or join conditions. Only use information provided in the Table Information.\n",
    "\n",
    "#         SQL Query:\n",
    "#         {query}\n",
    "\n",
    "#         Table Information:\n",
    "#         {tableInfo}\n",
    "\n",
    "#         Rules to check:\n",
    "#         1. All table names used in the query exist in the Table Information.\n",
    "#         2. All column names used in the query exist in their respective tables as per the Table Information.\n",
    "#         3. Join conditions use existing tables and columns.\n",
    "#         4. The query structure is valid PostgreSQL syntax.\n",
    "#         5. No subqueries are used (CTEs are allowed).\n",
    "#         6. The query addresses the User Query without adding extraneous information.\n",
    "\n",
    "#         User Query: {userQuery}\n",
    "\n",
    "#         If the query violates any rules or is not runnable, provide a corrected version. \n",
    "#         If the query is correct and follows all rules, return it as is.\n",
    "\n",
    "#         Corrected SQL Query:\n",
    "#         \"\"\"\n",
    "#         crag_prompt = PromptTemplate.from_template(crag_template)\n",
    "#         crag_chain = crag_prompt | self.llm\n",
    "#         crag_result = crag_chain.invoke({\n",
    "#             \"query\": query,\n",
    "#             \"tableInfo\": self.tableInfo,\n",
    "#             \"userQuery\": userQuery\n",
    "#         })\n",
    "#         return cleanSqlQuery(crag_result.content)\n",
    "\n",
    "#     def processUserQuery(self, userQuery: str) -> str:\n",
    "#         try:\n",
    "#             potentialTables = self._selectPotentialTables(userQuery)\n",
    "#             joinConditions = self._determineJoinConditions(potentialTables)\n",
    "#             filteringColumns = self._selectFilteringColumns(potentialTables, userQuery)\n",
    "            \n",
    "#             distinctQueryResult = self._executeQueryWithRetry(\n",
    "#                 self._generateDistinctQuery,\n",
    "#                 potentialTables,\n",
    "#                 joinConditions,\n",
    "#                 filteringColumns\n",
    "#             )\n",
    "            \n",
    "#             filterValues = self._determineFilterValues(distinctQueryResult, userQuery)\n",
    "            \n",
    "#             finalQueryResult = self._executeQueryWithRetry(\n",
    "#                 self._generateFinalQuery,\n",
    "#                 potentialTables,\n",
    "#                 joinConditions,\n",
    "#                 filteringColumns,\n",
    "#                 filterValues,\n",
    "#                 userQuery\n",
    "#             )\n",
    "            \n",
    "#             return self._summarizeResult(finalQueryResult, userQuery)\n",
    "#         except InvalidUserQueryException as e:\n",
    "#             return str(e)\n",
    "#         except NoDataFoundException as e:\n",
    "#             return str(e)\n",
    "#         except Exception as e:\n",
    "#             return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "#     def _summarizeResult(self, queryResult: pd.DataFrame, userQuery: str) -> str:\n",
    "#         template = \"\"\"\n",
    "#         Summarize the following query result in response to the user's question. Provide key insights and relevant statistics.\n",
    "        \n",
    "#         User Query: {userQuery}\n",
    "        \n",
    "#         Query Result:\n",
    "#         {queryResult}\n",
    "        \n",
    "#         Summary:\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate.from_template(template)\n",
    "#         chain = prompt | self.llm\n",
    "#         result = chain.invoke({\"userQuery\": userQuery, \"queryResult\": queryResult.to_json(orient='records')})\n",
    "#         return result.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "backend_dir = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "\n",
    "\n",
    "from aiStuff.workflows import DatasetRegionMatcher\n",
    "workflow = DatasetRegionMatcher()\n",
    "workflow.match(\"Where do the renters live in Wills?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiStuff.workflows import DatasetRegionMatcher\n",
    "from aiStuff.agentHelpers import DataFetcher\n",
    "\n",
    "\n",
    "class CombinedWorkflow:\n",
    "    def __init__(self):\n",
    "        self.matcher = DatasetRegionMatcher()\n",
    "        self.fetcher = DataFetcher()\n",
    "\n",
    "    async def process_query(self, user_query: str):\n",
    "        match_result = self.matcher.match(user_query)\n",
    "        layers = match_result.get('layers', [])\n",
    "\n",
    "        if not layers:\n",
    "            raise ValueError(\"No relevant dataset or region found for the query\")\n",
    "        \n",
    "        results = []\n",
    "        try:\n",
    "            for layer in layers:\n",
    "                print(layer)\n",
    "                region_id, dataset_id, level = layer\n",
    "                dataset_id = int(dataset_id)\n",
    "                region_id = int(region_id) if region_id else None\n",
    "                result = await self.fetcher.get_dataset_with_data(dataset_id, region_id)\n",
    "                results.append(result)\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error fetching data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = CombinedWorkflow()\n",
    "await workflow.process_query(\"Where do the renters live in Wills?\")\n",
    "# await workflow.process_query(\"Is the Greens vote correlated to the number of renters?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# API base URL\n",
    "BASE_URL = \"http://127.0.0.1:8000/api\"\n",
    "\n",
    "def test_handle_send(content, user_id, chat_id=None):\n",
    "    url = f\"{BASE_URL}/messages/send\"\n",
    "    data = {\"content\": content, \"chatId\": chat_id}\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.post(url, json=data, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_get_latest_messages(chat_id, user_id, limit=2):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/latest\"\n",
    "    params = {\"userId\": user_id, \"limit\": limit}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_fetch_messages(chat_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/messages\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_fetch_chat_history(user_id):\n",
    "    url = f\"{BASE_URL}/chats/all\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_pin_chat(chat_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/pin\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.put(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_unpin_chat(chat_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/unpin\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.put(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_search(term, user_id):\n",
    "    url = f\"{BASE_URL}/chats/search\"\n",
    "    params = {\"term\": term, \"userId\": user_id}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_archive_chat(chat_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/archive\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.put(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_unarchive_chat(chat_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/unarchive\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.put(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_update_chat_title(chat_id, new_title, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/title\"\n",
    "    params = {\"userId\": user_id, \"newTitle\": new_title}\n",
    "    response = requests.put(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_copy_message(chat_id, message_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/messages/{message_id}\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_update_message(chat_id, message_id, new_content, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/messages/{message_id}\"\n",
    "    params = {\"userId\": user_id, \"newContent\": new_content}\n",
    "    response = requests.put(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_handle_delete_chat(chat_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/delete\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.delete(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_upload_file(chat_id, user_id, file_path):\n",
    "    url = f\"{BASE_URL}/{chat_id}/upload\"\n",
    "    params = {\"userId\": user_id}\n",
    "    files = {'file': open(file_path, 'rb')}\n",
    "    response = requests.post(url, params=params, files=files)\n",
    "    return response.json()\n",
    "\n",
    "def test_update_group_status(chatId, user_id, group_name, group_color):\n",
    "    url = f\"{BASE_URL}/chats/{chatId}/group\"\n",
    "    params = {\"userId\": user_id}\n",
    "    data = {\"groupName\": group_name, \"groupColor\": group_color}\n",
    "    response = requests.put(url, params=params, json=data)\n",
    "    return response.json()\n",
    "\n",
    "def test_fetch_uploaded_files(chat_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/files\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def test_download_file(doc_id, user_id):\n",
    "    url = f\"{BASE_URL}/files/{doc_id}/download\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response\n",
    "\n",
    "def test_delete_document(chat_id, doc_id, user_id):\n",
    "    url = f\"{BASE_URL}/chats/{chat_id}/documents/{doc_id}\"\n",
    "    params = {\"userId\": user_id}\n",
    "    response = requests.delete(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "# Test cases\n",
    "user_id = 'example_user_id'\n",
    "\n",
    "print(\"Testing addMessage for a new user...\")\n",
    "result = test_handle_send(\"How many votes did each party get in 2022\", user_id=user_id)\n",
    "print(result)\n",
    "chat_id = result['chatId']\n",
    "\n",
    "print(\"Testing addMessage for the new chat...\")\n",
    "test_handle_send(\"Give me result for top 10 parties.\", chat_id=chat_id, user_id=user_id)\n",
    "\n",
    "print(\"Testing get latest messages...\")\n",
    "latest_msgs = test_get_latest_messages(chat_id, user_id)\n",
    "print(latest_msgs)\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing fetch messages...\")\n",
    "msgs = test_fetch_messages(chat_id, user_id)\n",
    "message_id = msgs[2]['messageId']\n",
    "print(msgs)\n",
    "print(\"*--\"*20)\n",
    "\n",
    "new_title = 'New Chat Title'\n",
    "new_content = 'Just Give me names of top 3 parties.'\n",
    "\n",
    "print(\"Testing fetch chat history...\")\n",
    "print(test_fetch_chat_history(user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing handle pin chat...\")\n",
    "print(test_handle_pin_chat(chat_id, user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing handle unpin chat...\")\n",
    "print(test_handle_unpin_chat(chat_id, user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing handle search...\")\n",
    "print(test_handle_search('party', user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing handle archive chat...\")\n",
    "print(test_handle_archive_chat(chat_id, user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing handle unarchive chat...\")\n",
    "print(test_handle_unarchive_chat(chat_id, user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing handle update chat title...\")\n",
    "print(test_handle_update_chat_title(chat_id, new_title, user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing copy message...\")\n",
    "print(test_copy_message(chat_id, message_id, user_id))\n",
    "print(\"*--\"*20)\n",
    "\n",
    "# print(\"Testing handle update message...\")\n",
    "# print(test_handle_update_message(chat_id, message_id, new_content, user_id))\n",
    "# print(\"*--\"*20)\n",
    "\n",
    "# New tests for file upload, download, and deletion\n",
    "print(\"Testing file upload...\")\n",
    "file_path = 'test_file.txt'  # Make sure this file exists in the same directory\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write(\"This is a test file for upload.\")\n",
    "upload_result = test_upload_file(chat_id, user_id, file_path)\n",
    "print(upload_result)\n",
    "os.remove(file_path)  # Clean up the test file\n",
    "print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing fetch uploaded files...\")\n",
    "uploaded_files = test_fetch_uploaded_files(chat_id, user_id)\n",
    "print(uploaded_files)\n",
    "print(\"*--\"*20)\n",
    "\n",
    "if uploaded_files['files']:\n",
    "    doc_id = uploaded_files['files'][0]['docId']\n",
    "    print(f\"Testing download file with docId: {doc_id}\")\n",
    "    download_response = test_download_file(doc_id, user_id)\n",
    "    \n",
    "    if download_response.status_code == 200:\n",
    "        print(\"File downloaded successfully\")\n",
    "        print(f\"Content-Type: {download_response.headers['Content-Type']}\")\n",
    "        print(f\"Content-Disposition: {download_response.headers['Content-Disposition']}\")\n",
    "        print(f\"File content: {download_response.content[:100]}...\")  # Print first 100 bytes\n",
    "    else:\n",
    "        print(f\"Failed to download file. Status code: {download_response.status_code}\")\n",
    "    print(\"*--\"*20)\n",
    "\n",
    "    print(\"Testing delete document...\")\n",
    "    delete_result = test_delete_document(chat_id, doc_id, user_id)\n",
    "    print(delete_result)\n",
    "    print(\"*--\"*20)\n",
    "\n",
    "    print(\"Verifying document deletion...\")\n",
    "    uploaded_files_after_deletion = test_fetch_uploaded_files(chat_id, user_id)\n",
    "    print(uploaded_files_after_deletion)\n",
    "    print(\"*--\"*20)\n",
    "\n",
    "print(\"Testing update group status...\")\n",
    "print(test_update_group_status(chat_id, user_id, \"TestGroup\", \"blue\"))\n",
    "print(\"*--\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing handle update chat title...\")\n",
    "print(test_handle_update_chat_title(chat_id, \"Top parties in 2022\", user_id))\n",
    "print(\"*--\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing handle delete chat...\")\n",
    "print(test_handle_delete_chat(chat_id, user_id))\n",
    "print(\"*--\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Workflow unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiStuff.agentHelpers import loadPostgresDatabase, cleanSqlQuery, cleanSummaryResponse, QuerySQLTool, InvalidUserQueryException, NoDataFoundException, loadLLM\n",
    "from aiStuff.customAgents import SqlExpert, ResponseSummarizer\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "load_dotenv(dotenv_path='./resources/.ENV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qn1 = 'How many votes did each party get in 2022'\n",
    "qn2 = 'Give me result for top 10 parties.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbName = os.getenv(\"ELECDATA_DB_NAME\")\n",
    "llm = loadLLM()\n",
    "sqlCoderAgent = SqlExpert(llm=llm)\n",
    "sqlQueryTool = QuerySQLTool(dbName=dbName)\n",
    "responseSummarizerAgent = ResponseSummarizer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableInfo = None\n",
    "with loadPostgresDatabase(dbName) as db:\n",
    "    tableInfo = db.get_table_info()\n",
    "\n",
    "def _generateQuery(userQuery: str, chatHistory: str = '') -> str:\n",
    "    \n",
    "    try:\n",
    "        sqlQuery = sqlCoderAgent.generateAndRefineQuery(\n",
    "            userQuery=userQuery,\n",
    "            dialect='postgres',\n",
    "            tableInfo=tableInfo,\n",
    "            chatHistory=chatHistory\n",
    "        )\n",
    "        sqlQuery = cleanSqlQuery(sqlQuery)\n",
    "        return sqlQuery\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error generating SQL query: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def _executeSqlQuery(sqlQuery):\n",
    "    try:\n",
    "        data = sqlQueryTool.executeQuery(sqlQuery)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error executing SQL query: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlQuery = _generateQuery(qn1)\n",
    "logger.info(f\"Generated SQL Query: {sqlQuery}\")\n",
    "data = _executeSqlQuery(sqlQuery)\n",
    "logger.info(f\"SQL Query executed successfully. Data retrieved: {data}\")\n",
    "res1 = responseSummarizerAgent.generateSummaryWithReflection(response=data.to_string(), userQuery=qn1)\n",
    "res1 = cleanSummaryResponse(res1)\n",
    "logger.info(f\"Response generated: {res1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = cleanSummaryResponse(res1)\n",
    "logger.info(f\"Response generated: {res1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatHistory = '\\n'.join([qn1, res1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlQuery = _generateQuery(qn2, chatHistory)\n",
    "logger.info(f\"Generated SQL Query: {sqlQuery}\")\n",
    "data = _executeSqlQuery(sqlQuery)\n",
    "logger.info(f\"SQL Query executed successfully. Data retrieved: {data}\")\n",
    "res2 = responseSummarizerAgent.generateSummaryWithReflection(response=data.to_string(), userQuery=qn2)\n",
    "res2 = cleanSummaryResponse(res2)\n",
    "logger.info(f\"Response generated: {res2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA for Datasets-Regions Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resources/datasets.json\", 'r') as file:\n",
    "    datasets = json.load(file)\n",
    "\n",
    "with open(\"resources/regions.json\", 'r') as file:\n",
    "    regions = json.load(file)\n",
    "\n",
    "\n",
    "datasets = datasets['datasets']\n",
    "regions = regions['regions']\n",
    "print(f\"We have {len(datasets)} datasets. and {len(regions)} regions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select all unique type in datasets:\n",
    "type = dict()\n",
    "for data in datasets:\n",
    "    type[data['type']] = type.get(data['type'], 0) + 1\n",
    "    \n",
    "type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select all unique level in datasets:\n",
    "levels = dict()\n",
    "for data in datasets:\n",
    "    levels[data['level']] = levels.get(data['level'], 0) + 1\n",
    "    \n",
    "levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select all unique series in datasets:\n",
    "series = dict()\n",
    "for data in datasets:\n",
    "    series[data['series_name']] = series.get(data['series_name'], 0) + 1\n",
    "    \n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select all unique Source-Name in datasets:\n",
    "sourceName = dict()\n",
    "for data in datasets:\n",
    "    sourceName[data['source']['name']] = sourceName.get(data['source']['name'], 0) + 1\n",
    "    \n",
    "sourceName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Metadata Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "backend_dir = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "sys.path.append(backend_dir)\n",
    "print(sys.path)\n",
    "\n",
    "# Now try to import\n",
    "from aiStuff.agentHelpers import ResourceManager, loadMetadata\n",
    "\n",
    "print(\"Import successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = ResourceManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.processResources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadMetadata('metadata', 'Regions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Regions-Dataset-Matcher and DataFetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from aiStuff.workflows import DatasetRegionMatcher\n",
    "from aiStuff.agentHelpers import DataFetcher\n",
    "\n",
    "workflow = DatasetRegionMatcher()\n",
    "fetcher = DataFetcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qns_list = \"\"\"Where do the renters live in Wills? \n",
    "Is the Greens vote correlated to the number of renters? \n",
    "What is the percentage of renters in the Wills electorate?\n",
    "How has the number of renters in Wills changed over the last 10 years?\n",
    "Are there more renters in suburbs closer to the city in Wills?\n",
    "Which suburbs in Wills have the highest concentration of renters?\n",
    "Is there a relationship between income levels and rental rates in Wills?\n",
    "How does the proportion of renters in Wills compare to the overall state average?\n",
    "Is the number of renters in Wills correlated with high Green Party votes across suburbs?\n",
    "Does the level of home ownership impact political preferences in Wills?\n",
    "Which suburb in Wills has the most renters voting for the Greens?\n",
    "How does the demographic breakdown of renters in Wills influence voter turnout?\n",
    "What are the age distributions across different suburbs within a specific electorate, and how might this impact voting trends?\n",
    "How do household income levels vary across different SA1 regions in a given electorate?\n",
    "What is the relationship between education levels and voting preferences in various SA1 regions?\n",
    "How does the employment rate correlate with voting patterns within different SA1 areas?\n",
    "Are there any observable trends between the concentration of recent immigrants in certain SA1 regions and the political parties they are more likely to support?\n",
    "What is the distribution of homeowners vs. renters across different SA1s, and how does this influence local voting behavior?\n",
    "How do household compositions (e.g., single-family, multi-family, shared housing) vary by SA1, and what impact might this have on voting outcomes?\n",
    "What is the voter turnout in different SA1 regions, and how does this compare to population density?\n",
    "How do geographical factors, such as proximity to the city center, affect voting preferences in the electorate?\n",
    "Is there a noticeable difference in voting behavior between urban, suburban, and rural areas within an electorate?\n",
    "How do different transportation accessibility levels (e.g., public transport, roads) across SA1s influence voter participation?\n",
    "What is the distribution of polling booth locations, and does proximity to these booths affect voter turnout in various suburbs?\n",
    "Are there patterns in how voters in specific SA1 regions align themselves with local vs. national issues?\n",
    "How do the boundaries of polling booths overlap with key demographic features in the SA1 data (e.g., income, age)?\n",
    "Which SA1 regions have the highest concentration of swing voters based on historical election results and demographic shifts?\n",
    "How do social service facilities (e.g., schools, hospitals) in different SA1 areas relate to political party support?\n",
    "What are the key socioeconomic factors that political campaigns should focus on in specific SA1 regions to maximize voter engagement?\n",
    "Are there specific SA1 regions where targeted campaign strategies (e.g., door-to-door canvassing, digital advertising) would be more effective?\n",
    "How does the correlation between household income and party support vary across different electorates?\n",
    "What is the impact of recent infrastructure developments in certain SA1s on local voting patterns?\n",
    "How does the proportion of different household types (e.g., single-parent, elderly) in SA1 regions influence key policy concerns (e.g., healthcare, education)?\n",
    "How do changes in local unemployment rates affect voter turnout and party preferences across SA1 regions?\n",
    "What are the most common policy issues in SA1 regions with higher youth populations, and how do these influence voting behavior?\n",
    "How do environmental concerns (e.g., green spaces, pollution levels) vary between SA1s, and what is their correlation with support for the Green Party?\n",
    "How does access to affordable housing in various SA1s correlate with party support?\n",
    "How have demographic changes over the last decade in different SA1 regions affected shifts in political preferences?\n",
    "Which SA1 regions have seen the most significant changes in voter registration, and how has this impacted election outcomes?\n",
    "How do changes in population density within certain SA1 regions affect the distribution of polling booth locations?\n",
    "Have there been changes in voter turnout patterns in specific SA1 areas over the last three federal elections?\n",
    "How has the proportion of absentee ballots or early voting changed in various SA1 regions, and what does this suggest about local voter behavior?\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "questions = qns_list.split(\"\\n\")\n",
    "performance = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qn in questions:\n",
    "    layers = workflow.match(userQuery= qn)\n",
    "    # print(f\"User Query: {qn}\\nLayers:{layers}\")\n",
    "    performance[qn] = layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(performance)\n",
    "df = df.T.reset_index()\n",
    "df.columns = ['UserQuery', 'Identified Layers']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(42):\n",
    "#     try:\n",
    "#         if type(df['Identified Layers'].iloc[idx]) == str:\n",
    "#             json.loads(df['Identified Layers'].iloc[idx].replace(\"'\", '\"'))\n",
    "#         else:\n",
    "#             json.loads(df['Identified Layers'].iloc[idx])\n",
    "#         print(f\"Success with: {idx}, type: {type(df['Identified Layers'].iloc[idx])}\", df['Identified Layers'].iloc[idx])\n",
    "#     except:\n",
    "#         print(f\"Issue with: {idx}, type: {type(df['Identified Layers'].iloc[idx])}\", df['Identified Layers'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), '..')), 'resources')\n",
    "\n",
    "with open(os.path.join(resources_path, 'datasets.json'), 'r') as f:\n",
    "    datasets = json.loads(f.read())\n",
    "\n",
    "with open(os.path.join(resources_path, 'regions.json'), 'r') as f:\n",
    "    regions = json.loads(f.read())\n",
    "\n",
    "datasets = datasets['datasets']\n",
    "regions = regions['regions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptions(layers):\n",
    "    desc = ''\n",
    "    cnt = 0\n",
    "    if type(layers) == str:\n",
    "        layers = json.loads(layers.replace(\"'\", '\"'))\n",
    "    for regionID, datasetID, level in layers:\n",
    "        dataset = list(filter(lambda x: str(x['id']) == datasetID, datasets))\n",
    "        region = list(filter(lambda x: str(x['id']) == regionID, regions))\n",
    "\n",
    "        desc += f\"Identified Layer{cnt + 1}:\\n\"\n",
    "        if dataset:\n",
    "            desc += f\"Dataset:{dataset[0]['display_name']}\\n\"\n",
    "        if region:\n",
    "            desc += f\"Region:{region[0]['display_name']}\\n\"\n",
    "        if level:\n",
    "            desc += f\"Level: {level}\\n\"\n",
    "        cnt += 1\n",
    "    \n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Description'] = df['Identified Layers'].apply(get_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(resources_path, 'DatasetRegionMatcher_Test_v2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in layers:\n",
    "#     cnt = 0\n",
    "#     for regionID, datasetID, level in layer:\n",
    "#         dataset = list(filter(lambda x: str(x['id']) == datasetID, datasets))\n",
    "#         region = list(filter(lambda x: str(x['id']) == regionID, regions))\n",
    "\n",
    "#         print(f\"Identified Layer{cnt + 1}:\")\n",
    "#         if dataset:\n",
    "#             print(f\"Dataset:{dataset[0]['display_name']}\")\n",
    "#         if region:\n",
    "#             print(f\"Region:{region[0]['display_name']}\")\n",
    "#         if level:\n",
    "#             print(f\"Level: {level}\")\n",
    "#         cnt += 1\n",
    "#     print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qn1 = \"Where do the renters live in Wills?\"\n",
    "qn2 = \"Is the Greens vote correlated to the number of renters?\"\n",
    "\n",
    "\n",
    "layers1 = workflow.match(userQuery= qn1)\n",
    "layers1 = layers1['layers']\n",
    "print(layers1)\n",
    "\n",
    "layers2 = workflow.match(userQuery= qn2)\n",
    "layers2 = layers2['layers']\n",
    "print(layers2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers2 = [['', '1001', 'SA1'], ['', '1015', 'top']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fetcher.get_datasets_with_data(layers2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiStuff.customAgents import AnalystAgent\n",
    "from aiStuff.agentHelpers import loadLLM\n",
    "\n",
    "llm = loadLLM()\n",
    "agent = AnalystAgent(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = \"\"\n",
    "for idx, data in enumerate(res[:1]):\n",
    "    df = data['data']\n",
    "    df_info += f\"\"\"DataFrame {idx}:\n",
    "        1. Head:\n",
    "        {df.head()}\n",
    "\n",
    "        2. Info:\n",
    "        {df.info()}\n",
    "\n",
    "        3. Description:\n",
    "        {df.describe()}\n",
    "\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code = agent.generateAnalysis(userQuery = \"Is the Greens vote correlated to the number of renters?\", dataframes_info = df_info).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code.replace(\"`\", \"\").split('python')[1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ELECDATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from aiStuff.workflows import ElecDataWorkflow\n",
    "workflow = ElecDataWorkflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qns_list = \"\"\"Where do the renters live in Wills?\n",
    "Is the Greens vote correlated to the number of renters? \n",
    "What is the percentage of renters in the Wills electorate?\n",
    "How has the number of renters in Wills changed over the last 10 years?\n",
    "Are there more renters in suburbs closer to the city in Wills?\n",
    "Which suburbs in Wills have the highest concentration of renters?\n",
    "Is there a relationship between income levels and rental rates in Wills?\n",
    "How does the proportion of renters in Wills compare to the overall state average?\n",
    "Is the number of renters in Wills correlated with high Green Party votes across suburbs?\n",
    "Does the level of home ownership impact political preferences in Wills?\n",
    "Which suburb in Wills has the most renters voting for the Greens?\n",
    "How does the demographic breakdown of renters in Wills influence voter turnout?\n",
    "What are the age distributions across different suburbs within a specific electorate, and how might this impact voting trends?\n",
    "How do household income levels vary across different SA1 regions in a given electorate?\n",
    "What is the relationship between education levels and voting preferences in various SA1 regions?\n",
    "How does the employment rate correlate with voting patterns within different SA1 areas?\n",
    "Are there any observable trends between the concentration of recent immigrants in certain SA1 regions and the political parties they are more likely to support?\n",
    "What is the distribution of homeowners vs. renters across different SA1s, and how does this influence local voting behavior?\n",
    "How do household compositions (e.g., single-family, multi-family, shared housing) vary by SA1, and what impact might this have on voting outcomes?\n",
    "What is the voter turnout in different SA1 regions, and how does this compare to population density?\n",
    "How do geographical factors, such as proximity to the city center, affect voting preferences in the electorate?\n",
    "Is there a noticeable difference in voting behavior between urban, suburban, and rural areas within an electorate?\n",
    "How do different transportation accessibility levels (e.g., public transport, roads) across SA1s influence voter participation?\n",
    "What is the distribution of polling booth locations, and does proximity to these booths affect voter turnout in various suburbs?\n",
    "Are there patterns in how voters in specific SA1 regions align themselves with local vs. national issues?\n",
    "How do the boundaries of polling booths overlap with key demographic features in the SA1 data (e.g., income, age)?\n",
    "Which SA1 regions have the highest concentration of swing voters based on historical election results and demographic shifts?\n",
    "How do social service facilities (e.g., schools, hospitals) in different SA1 areas relate to political party support?\n",
    "What are the key socioeconomic factors that political campaigns should focus on in specific SA1 regions to maximize voter engagement?\n",
    "Are there specific SA1 regions where targeted campaign strategies (e.g., door-to-door canvassing, digital advertising) would be more effective?\n",
    "How does the correlation between household income and party support vary across different electorates?\n",
    "What is the impact of recent infrastructure developments in certain SA1s on local voting patterns?\n",
    "How does the proportion of different household types (e.g., single-parent, elderly) in SA1 regions influence key policy concerns (e.g., healthcare, education)?\n",
    "How do changes in local unemployment rates affect voter turnout and party preferences across SA1 regions?\n",
    "What are the most common policy issues in SA1 regions with higher youth populations, and how do these influence voting behavior?\n",
    "How do environmental concerns (e.g., green spaces, pollution levels) vary between SA1s, and what is their correlation with support for the Green Party?\n",
    "How does access to affordable housing in various SA1s correlate with party support?\n",
    "How have demographic changes over the last decade in different SA1 regions affected shifts in political preferences?\n",
    "Which SA1 regions have seen the most significant changes in voter registration, and how has this impacted election outcomes?\n",
    "How do changes in population density within certain SA1 regions affect the distribution of polling booth locations?\n",
    "Have there been changes in voter turnout patterns in specific SA1 areas over the last three federal elections?\n",
    "How has the proportion of absentee ballots or early voting changed in various SA1 regions, and what does this suggest about local voter behavior?\"\"\"\n",
    "\n",
    "\n",
    "questions = qns_list.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Generated SQL Query: ```\n",
      "invalid user query - not related to the database.\n",
      "```\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.agentHelpers:whereConditions before parsing: []\n",
      "INFO:aiStuff.workflows:Extracted WHERE columns: []\n",
      "INFO:aiStuff.workflows:Context: \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Updated SQL Query: invalid user query - not related to the database.\n",
      "ERROR:aiStuff.workflows:Error executing SQL query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 134, in processUserQuery\n",
      "    data = self._executeSqlQuery(updatedQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Generated SQL Query: ```\n",
      "invalid user query - not related to the database.\n",
      "```\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.agentHelpers:whereConditions before parsing: []\n",
      "INFO:aiStuff.workflows:Extracted WHERE columns: []\n",
      "INFO:aiStuff.workflows:Context: \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Updated SQL Query: invalid user query - not related to the database.\n",
      "ERROR:aiStuff.workflows:Error executing SQL query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 134, in processUserQuery\n",
      "    data = self._executeSqlQuery(updatedQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the Database Schema or cannot be answered from the database\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 112, in processUserQuery\n",
      "    raise InvalidUserQueryException()\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the Database Schema or cannot be answered from the database\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the Database Schema or cannot be answered from the database\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 112, in processUserQuery\n",
      "    raise InvalidUserQueryException()\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the Database Schema or cannot be answered from the database\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the Database Schema or cannot be answered from the database\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 112, in processUserQuery\n",
      "    raise InvalidUserQueryException()\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the Database Schema or cannot be answered from the database\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Generated SQL Query: ```\n",
      "invalid user query - not related to the database.\n",
      "```\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.agentHelpers:whereConditions before parsing: []\n",
      "INFO:aiStuff.workflows:Extracted WHERE columns: []\n",
      "INFO:aiStuff.workflows:Context: \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Updated SQL Query: invalid user query - not related to the database.\n",
      "ERROR:aiStuff.workflows:Error executing SQL query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 134, in processUserQuery\n",
      "    data = self._executeSqlQuery(updatedQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Generated SQL Query: ```\n",
      "invalid user query - not related to the database.\n",
      "```\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.agentHelpers:whereConditions before parsing: []\n",
      "INFO:aiStuff.workflows:Extracted WHERE columns: []\n",
      "INFO:aiStuff.workflows:Context: \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Updated SQL Query: invalid user query - not related to the database.\n",
      "ERROR:aiStuff.workflows:Error executing SQL query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 134, in processUserQuery\n",
      "    data = self._executeSqlQuery(updatedQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Generated SQL Query: ```\n",
      "invalid user query - not related to the database.\n",
      "```\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.agentHelpers:whereConditions before parsing: []\n",
      "INFO:aiStuff.workflows:Extracted WHERE columns: []\n",
      "INFO:aiStuff.workflows:Context: \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Updated SQL Query: invalid user query - not related to the database.\n",
      "ERROR:aiStuff.workflows:Error executing SQL query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 134, in processUserQuery\n",
      "    data = self._executeSqlQuery(updatedQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the Database Schema or cannot be answered from the database\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 112, in processUserQuery\n",
      "    raise InvalidUserQueryException()\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the Database Schema or cannot be answered from the database\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Generated SQL Query: ```\n",
      "invalid user query - not related to the database.\n",
      "```\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.agentHelpers:whereConditions before parsing: []\n",
      "INFO:aiStuff.workflows:Extracted WHERE columns: []\n",
      "INFO:aiStuff.workflows:Context: \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Updated SQL Query: invalid user query - not related to the database.\n",
      "ERROR:aiStuff.workflows:Error executing SQL query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 134, in processUserQuery\n",
      "    data = self._executeSqlQuery(updatedQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the Database Schema or cannot be answered from the database\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 112, in processUserQuery\n",
      "    raise InvalidUserQueryException()\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the Database Schema or cannot be answered from the database\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the Database Schema or cannot be answered from the database\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 112, in processUserQuery\n",
      "    raise InvalidUserQueryException()\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the Database Schema or cannot be answered from the database\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the Database Schema or cannot be answered from the database\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 112, in processUserQuery\n",
      "    raise InvalidUserQueryException()\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the Database Schema or cannot be answered from the database\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Generated SQL Query: ```\n",
      "invalid user query - not related to the database.\n",
      "```\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.agentHelpers:whereConditions before parsing: []\n",
      "INFO:aiStuff.workflows:Extracted WHERE columns: []\n",
      "INFO:aiStuff.workflows:Context: \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Updated SQL Query: invalid user query - not related to the database.\n",
      "ERROR:aiStuff.workflows:Error executing SQL query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 134, in processUserQuery\n",
      "    data = self._executeSqlQuery(updatedQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the Database Schema or cannot be answered from the database\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 112, in processUserQuery\n",
      "    raise InvalidUserQueryException()\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the Database Schema or cannot be answered from the database\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Generated SQL Query: ```\n",
      "invalid user query - not related to the database.\n",
      "```\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.agentHelpers:whereConditions before parsing: []\n",
      "INFO:aiStuff.workflows:Extracted WHERE columns: []\n",
      "INFO:aiStuff.workflows:Context: \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Updated SQL Query: invalid user query - not related to the database.\n",
      "ERROR:aiStuff.workflows:Error executing SQL query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 134, in processUserQuery\n",
      "    data = self._executeSqlQuery(updatedQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Generated SQL Query: ```\n",
      "invalid user query - not related to the database.\n",
      "```\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.agentHelpers:whereConditions before parsing: []\n",
      "INFO:aiStuff.workflows:Extracted WHERE columns: []\n",
      "INFO:aiStuff.workflows:Context: \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Updated SQL Query: invalid user query - not related to the database.\n",
      "ERROR:aiStuff.workflows:Error executing SQL query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 134, in processUserQuery\n",
      "    data = self._executeSqlQuery(updatedQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Generated SQL Query: ```\n",
      "invalid user query - not related to the database.\n",
      "```\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.agentHelpers:whereConditions before parsing: []\n",
      "INFO:aiStuff.workflows:Extracted WHERE columns: []\n",
      "INFO:aiStuff.workflows:Context: \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Updated SQL Query: invalid user query - not related to the database.\n",
      "ERROR:aiStuff.workflows:Error executing SQL query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 134, in processUserQuery\n",
      "    data = self._executeSqlQuery(updatedQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Generated SQL Query: ```\n",
      "invalid user query - not related to the database.\n",
      "```\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.agentHelpers:whereConditions before parsing: []\n",
      "INFO:aiStuff.workflows:Extracted WHERE columns: []\n",
      "INFO:aiStuff.workflows:Context: \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiStuff.workflows:Updated SQL Query: invalid user query - not related to the database.\n",
      "ERROR:aiStuff.workflows:Error executing SQL query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "ERROR:aiStuff.workflows:Invalid user query: Query is not related to the database schema.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 134, in processUserQuery\n",
      "    data = self._executeSqlQuery(updatedQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py\", line 85, in _executeSqlQuery\n",
      "    data = self.sqlQueryTool.executeQuery(sqlQuery)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\agentHelpers.py\", line 480, in executeQuery\n",
      "    raise InvalidUserQueryException(\"Query is not related to the database schema.\")\n",
      "aiStuff.agentHelpers.InvalidUserQueryException: Query is not related to the database schema.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m performance \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m qn \u001b[38;5;129;01min\u001b[39;00m questions:\n\u001b[1;32m----> 3\u001b[0m     workflow \u001b[38;5;241m=\u001b[39m \u001b[43mElecDataWorkflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     res \u001b[38;5;241m=\u001b[39m workflow\u001b[38;5;241m.\u001b[39mprocessUserQuery(qn)\n\u001b[0;32m      5\u001b[0m     performance[qn] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py:54\u001b[0m, in \u001b[0;36mElecDataWorkflow.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtableInfo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setTableInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setDialect()\n",
      "File \u001b[1;32mc:\\Users\\rajna\\Desktop\\Swinburne\\Semester 4\\TAP\\PoliQ_App\\backend\\aiStuff\\workflows.py:61\u001b[0m, in \u001b[0;36mElecDataWorkflow._setTableInfo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m table_list \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mget_usable_table_names()\n\u001b[0;32m     60\u001b[0m table_list \u001b[38;5;241m=\u001b[39m [table \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m table_list \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (table\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m table\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdjango\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtableInfo \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_table_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rajna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\utilities\\sql_database.py:356\u001b[0m, in \u001b[0;36mSQLDatabase.get_table_info\u001b[1;34m(self, table_names)\u001b[0m\n\u001b[0;32m    354\u001b[0m     table_info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_table_indexes(table)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_rows_in_table_info:\n\u001b[1;32m--> 356\u001b[0m     table_info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_sample_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_extra_info:\n\u001b[0;32m    358\u001b[0m     table_info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rajna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\utilities\\sql_database.py:378\u001b[0m, in \u001b[0;36mSQLDatabase._get_sample_rows\u001b[1;34m(self, table)\u001b[0m\n\u001b[0;32m    374\u001b[0m columns_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([col\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39mcolumns])\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# get the sample rows\u001b[39;00m\n\u001b[1;32m--> 378\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_rows_result\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# shorten values in the sample rows\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\rajna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:235\u001b[0m, in \u001b[0;36mConnection.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, type_: Any, value: Any, traceback: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rajna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1242\u001b[0m, in \u001b[0;36mConnection.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Close this :class:`_engine.Connection`.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03mThis results in a release of the underlying database\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1238\u001b[0m \n\u001b[0;32m   1239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction:\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transaction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1243\u001b[0m     skip_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rajna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2586\u001b[0m, in \u001b[0;36mTransaction.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2575\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Close this :class:`.Transaction`.\u001b[39;00m\n\u001b[0;32m   2576\u001b[0m \n\u001b[0;32m   2577\u001b[0m \u001b[38;5;124;03mIf this transaction is the base transaction in a begin/commit\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2583\u001b[0m \n\u001b[0;32m   2584\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2585\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2586\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2587\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2588\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_active\n",
      "File \u001b[1;32mc:\\Users\\rajna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2724\u001b[0m, in \u001b[0;36mRootTransaction._do_close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2723\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_close\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2724\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_close_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rajna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2710\u001b[0m, in \u001b[0;36mRootTransaction._close_impl\u001b[1;34m(self, try_deactivate)\u001b[0m\n\u001b[0;32m   2708\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2709\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_active:\n\u001b[1;32m-> 2710\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_rollback_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2712\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39m_nested_transaction:\n\u001b[0;32m   2713\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39m_nested_transaction\u001b[38;5;241m.\u001b[39m_cancel()\n",
      "File \u001b[1;32mc:\\Users\\rajna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2702\u001b[0m, in \u001b[0;36mRootTransaction._connection_rollback_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2701\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_connection_rollback_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2702\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rollback_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rajna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1129\u001b[0m, in \u001b[0;36mConnection._rollback_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_rollback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection)\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1129\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rajna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2356\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2354\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2355\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2356\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m   2357\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2358\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[1;32mc:\\Users\\rajna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1127\u001b[0m, in \u001b[0;36mConnection._rollback_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1125\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROLLBACK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1127\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_rollback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(e, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\rajna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:698\u001b[0m, in \u001b[0;36mDefaultDialect.do_rollback\u001b[1;34m(self, dbapi_connection)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_rollback\u001b[39m(\u001b[38;5;28mself\u001b[39m, dbapi_connection):\n\u001b[1;32m--> 698\u001b[0m     \u001b[43mdbapi_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "performance = {}\n",
    "for qn in questions:\n",
    "    workflow = ElecDataWorkflow()\n",
    "    res = workflow.processUserQuery(qn)\n",
    "    performance[qn] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Where do the renters live in Wills?': 'Query is not related to the database schema.',\n",
       " 'Is the Greens vote correlated to the number of renters? ': 'Query is not related to the database schema.',\n",
       " 'What is the percentage of renters in the Wills electorate?': 'Query is not related to the Database Schema or cannot be answered from the database',\n",
       " 'How has the number of renters in Wills changed over the last 10 years?': 'Query is not related to the Database Schema or cannot be answered from the database',\n",
       " 'Are there more renters in suburbs closer to the city in Wills?': 'Query is not related to the Database Schema or cannot be answered from the database',\n",
       " 'Which suburbs in Wills have the highest concentration of renters?': 'Query is not related to the database schema.',\n",
       " 'Is there a relationship between income levels and rental rates in Wills?': \"I'm sorry, but I don't have any information on the relationship between income levels and rental rates in Wills from the chat history. If you have more specific details or data you'd like to discuss, feel free to share, and I'll do my best to assist you!\",\n",
       " 'How does the proportion of renters in Wills compare to the overall state average?': 'Query is not related to the database schema.',\n",
       " 'Is the number of renters in Wills correlated with high Green Party votes across suburbs?': 'Query is not related to the database schema.',\n",
       " 'Does the level of home ownership impact political preferences in Wills?': 'Query is not related to the Database Schema or cannot be answered from the database',\n",
       " 'Which suburb in Wills has the most renters voting for the Greens?': 'Query is not related to the database schema.',\n",
       " 'How does the demographic breakdown of renters in Wills influence voter turnout?': 'Query is not related to the Database Schema or cannot be answered from the database',\n",
       " 'What are the age distributions across different suburbs within a specific electorate, and how might this impact voting trends?': 'Query is not related to the Database Schema or cannot be answered from the database',\n",
       " 'How do household income levels vary across different SA1 regions in a given electorate?': 'Query is not related to the Database Schema or cannot be answered from the database',\n",
       " 'What is the relationship between education levels and voting preferences in various SA1 regions?': 'Query is not related to the database schema.',\n",
       " 'How does the employment rate correlate with voting patterns within different SA1 areas?': 'Query is not related to the Database Schema or cannot be answered from the database',\n",
       " 'Are there any observable trends between the concentration of recent immigrants in certain SA1 regions and the political parties they are more likely to support?': 'Query is not related to the database schema.',\n",
       " 'What is the distribution of homeowners vs. renters across different SA1s, and how does this influence local voting behavior?': 'Query is not related to the database schema.',\n",
       " 'How do household compositions (e.g., single-family, multi-family, shared housing) vary by SA1, and what impact might this have on voting outcomes?': 'Query is not related to the database schema.',\n",
       " 'What is the voter turnout in different SA1 regions, and how does this compare to population density?': 'Query is not related to the database schema.',\n",
       " 'How do geographical factors, such as proximity to the city center, affect voting preferences in the electorate?': \"I'm sorry, but I don't have any information on how geographical factors, such as proximity to the city center, affect voting preferences in the electorate from the chat history provided. If you have any specific questions or need information on a different topic, feel free to ask!\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from aiStuff.agentHelpers import populate_vectordb, get_relevant_documents, loadFromMongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "datameta = loadFromMongo('metadata', 'Datasets')\n",
    "datameta = json.loads(datameta)\n",
    "datameta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_vectordb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Where do the renters live in Wills?\"\n",
    "results = get_relevant_documents(query, 20)\n",
    "for doc, score in results:\n",
    "    print(f\"Document: {doc.metadata['id']}\")\n",
    "    print(f\"Similarity Score: {score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [(result.metadata['id']) for result, score in results]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datameta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Something New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
